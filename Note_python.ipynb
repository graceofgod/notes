{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "from __future__ import division # show flaoting number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "np.array([1.3333]) # show array([ 1.33])\n",
    "\n",
    "np.nan #nan\n",
    "np.inf #inf\n",
    "\n",
    "np.array#([], dtype=np.float64(np.int32, np.string))#([[],[]])#([[[],[]],[[],[]]])\n",
    "np.asarray#same as np.array\n",
    "\n",
    "####################################\n",
    "np.mgrid[0:3,0:2]\n",
    "#array([[[0, 0],\n",
    "#        [1, 1],\n",
    "#        [2, 2]],\n",
    "#       [[0, 1],\n",
    "#        [0, 1],\n",
    "#        [0, 1]]])\n",
    "\n",
    "x = [-1,0,1]\n",
    "y = [-2,0,-2]\n",
    "xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "#xx : array([[-1,  0,  1]])\n",
    "#yy : array([[-2],\n",
    "#            [ 0],\n",
    "#            [ 2]])\n",
    "np.concatenate([x, y]) #array([-1,  0,  1, -2,  0, -2])\n",
    "####################################\n",
    "x = np.array([[1,2,3], [4,5,6]])\n",
    "np.reshape(x,(3,2)) #array([[1, 2],[3, 4],[5, 6]])\n",
    "np.transpose(x) #array([[1, 2],[3, 4],[5, 6]])\n",
    "np.delete(x,2,1) # delete 2th col, axis=1 #array([[1, 2], [4, 5]])\n",
    "\n",
    "x=np.arange(24).reshape((2,3,4))\n",
    "#x=array([[[ 0,  1,  2,  3],\n",
    "#          [ 4,  5,  6,  7],\n",
    "#          [ 8,  9, 10, 11]],\n",
    "#        [[12, 13, 14, 15],\n",
    "#         [16, 17, 18, 19],\n",
    "#         [20, 21, 22, 23]]])\n",
    "x.transpose((0,2,1)) #the 1 and 2 axes exchage\n",
    "x.swapaxes(1,2)\n",
    "#array([[[ 0,  4,  8],\n",
    "#        [ 1,  5,  9],\n",
    "#        [ 2,  6, 10],\n",
    "#        [ 3,  7, 11]],\n",
    "#       [[12, 16, 20],\n",
    "#        [13, 17, 21],\n",
    "#        [14, 18, 22],\n",
    "#        [15, 19, 23]]])\n",
    "\n",
    "x =np.array([1,2,3,4,5,6,7,8])\n",
    "np.array_split(x, 2) \n",
    "np.split(x, 2)       \n",
    "#[array([1, 2, 3, 4]), array([5, 6, 7, 8])]\n",
    "np.split(x, [2,5,7])  #[array([1, 2]), array([3, 4, 5]), array([6, 7]), array([8])]\n",
    "\n",
    "np.ravel(x) \n",
    "x.flatten()\n",
    "#array([1, 2, 3, 4, 5, 6])\n",
    "np.repeat(x, 2) #array([1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6])\n",
    "np.repeat(x, [1, 2], axis=0)\n",
    "#array([[1, 2, 3],\n",
    "#       [4, 5, 6],\n",
    "#       [4, 5, 6]])\n",
    "np.tile(x,2)\n",
    "#array([[1, 2, 3, 1, 2, 3],\n",
    "#       [4, 5, 6, 4, 5, 6]])\n",
    "np.tile(x, [2,3])\n",
    "#array([[1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "#       [4, 5, 6, 4, 5, 6, 4, 5, 6],\n",
    "#       [1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "#       [4, 5, 6, 4, 5, 6, 4, 5, 6]])\n",
    "####################################\n",
    "x=np.array([1,2,3])\n",
    "np.atleast_2d(x)#array([[1, 2, 3]])\n",
    "x[np.newaxis,:] #array([[1, 2, 3]])\n",
    "\n",
    "x = np.array([[1,2], [3,4]]); y= np.array([[10,20], [30,40]])\n",
    "np.append(x,y)  #array([ 1,  2,  3,  4, 10, 20, 30, 40])\n",
    "np.vstack((x,y))\n",
    "np.r_[x,y]\n",
    "np.append(x,y,axis=0)\n",
    "np.concatenate((x, y), axis=0)\n",
    "#array([[ 1,  2],\n",
    "#       [ 3,  4],\n",
    "#       [10, 21],\n",
    "#       [30, 40]])\n",
    "np.hstack((x,y))\n",
    "np.c_[x,y]\n",
    "np.column_stack((x,y))\n",
    "np.append(x,y,axis=1)\n",
    "np.concatenate((x, y), axis=1)\n",
    "#array([[ 1,  2, 10, 20],\n",
    "#       [ 3,  4, 30, 40]])\n",
    "\n",
    "####################################\n",
    "x = [1,2]\n",
    "y = [3,4]\n",
    "np.subtract.outer(x,y) #1-[3,4] , 2-[3,4]\n",
    "#array([[-2, -3],\n",
    "#       [-1, -2]])\n",
    "np.add.outer(x,y)\n",
    "#array([[4, 5],\n",
    "#       [5, 6]])\n",
    "np.multiply.outer(x,y)\n",
    "#array([[3, 4],\n",
    "#       [6, 8]])\n",
    "np.divide.outer(x,y)\n",
    "np.multiply.reduce(x) #1*2=2 #multiply values at the same axis\n",
    "\n",
    "x = np.array([[1,2], [3,4]])\n",
    "np.multiply.reduce(x, axis=0) #array([3, 8])\n",
    "np.divide.reduce(x, axis=0) \n",
    "np.add.reduce(x, axis=0) \n",
    "np.subtract.reduce(x, axis=0) \n",
    "np.multiply.accumulate(x, axis=0) #array([[1, 2],[3, 8]])\n",
    "np.divide.accumulate(x, axis=0)\n",
    "np.add.accumulate(x, axis=0)\n",
    "np.subtract.accumulate(x, axis=0)\n",
    "\n",
    "x=[0, 1, 2, 3, 4, 5]\n",
    "np.multiply.reduceat(x,[1,3], axis=0) #array([ 2, 60]) #2=x[1]*x[2], 60=x[3]*x[4]*x[5]\n",
    "np.divide.reduceat(x,[1,3], axis=0)\n",
    "np.add.reduceat(x,[1,3], axis=0)\n",
    "np.subtract.reduceat(x,[1,3], axis=0)\n",
    "\n",
    "np.logical_not([True, False, 0, 1]) #array([False,  True,  True, False], dtype=bool) # T become F, 0 become True\n",
    "np.logical_and([True, True, False], [False, True, False])  #array([False,  True, False], dtype=bool)\n",
    "np.logical_xor([True, True, False], [False, True, False]) #array([ True, False, False], dtype=bool)\n",
    "np.logical_or([True, True, False], [False, True, False])  #array([ True,  True, False], dtype=bool)\n",
    "\n",
    "x=np.array([[True, True, False],[False, True, False]])\n",
    "np.logical_and.reduce(x, axis=0) #array([False,  True, False], dtype=bool)\n",
    "np.logical_xor.reduce(x, axis=0) \n",
    "np.logical_or.reduce(x, axis=0)\n",
    "np.where(x) #(array([0, 0, 1], dtype=int64), array([0, 1, 1], dtype=int64)) # show where is true\n",
    "\n",
    "x=np.array([[0, 1], [2,0]])\n",
    "np.where(x)  #(array([0, 1], dtype=int64), array([1, 0], dtype=int64))\n",
    "np.where(x>0, 1,-1)\n",
    "#array([[-1,  1],\n",
    "#       [ 1, -1]])\n",
    "\n",
    "np.in1d([1,2,3],[1,7]) #array([ True, False, False], dtype=bool)\n",
    "\n",
    "np.isclose([1,2,3], 1) #array([ True, False, False], dtype=bool) check if array elements have 1\n",
    "np.isclose([1,2,3], [1,2,5]) #array([ True,  True, False], dtype=bool)\n",
    "x=np.array([[True,False],[True,True]])\n",
    "np.all(x, axis=0) #check all array elements are True   check all array elements are True\n",
    "np.any(x, axis=0) #array([ True,  True], dtype=bool)   check any array elements is True\n",
    "x=np.array([[0,2],[3,np.nan]])\n",
    "np.all(x, axis=0) #array([False,  True], dtype=bool)\n",
    "np.any(x, axis=0) #array([ True,  True], dtype=bool\n",
    "\n",
    "np.isnan([np.nan,1,2])            #array([ True, False, False], dtype=bool)\n",
    "np.isfinite([np.nan,np.inf, 0,1]) #array([False, False,  True,  True], dtype=bool)\n",
    "np.isinf([np.nan,np.inf, 0,1])    #array([False,  True, False, False], dtype=bool)\n",
    "\n",
    "a=np.array([True,True,False]);b=np.array([3,6,9])\n",
    "b[~a]  #show array([9])\n",
    "b[a]   #show array([3, 6])\n",
    "b==3   #show array([ True, False, False]\n",
    "####################################\n",
    "np.zeros(3)=np.empty(3) #array([ 0.,  0.,  0.])\n",
    "np.zeros((2,3))=np.empty((2,3))\n",
    "#array([[ 0.,  0.,  0.],\n",
    "#       [ 0.,  0.,  0.]])\n",
    "np.zeros_like([1,2,3]) #array([0, 0, 0]) return an array of zeros with the same shape of x\n",
    "np.ones(3)  #array([ 1.,  1.,  1.])\n",
    "np.ones((2,3))\n",
    "np.eye(3)\n",
    "#array([[ 1.,  0.,  0.],\n",
    "#       [ 0.,  1.,  0.],\n",
    "#       [ 0.,  0.,  1.]])\n",
    "np.linspace(1, 2, num=5) #array([ 1.  ,  1.25,  1.5 ,  1.75,  2.  ])\n",
    "np.logspace(1, 2, num=5) #array([  10.  ,   17.78,   31.62,   56.23,  100.  ])\n",
    "\n",
    "np.arange(2,6) #array([2, 3, 4, 5])\n",
    "np.arange(2,6,2) #array([2, 4])\n",
    "np.arange(4).reshape((2,2))\n",
    "#array([[0, 1],\n",
    "#       [2, 3]])\n",
    "\n",
    "x = [4, 3, 5, 7, 6, 8]\n",
    "indices = [0, 1, 4]\n",
    "np.take(x, indices) #array([4, 3, 6])\n",
    "\n",
    "x = np.array([1,2,3,4,5])\n",
    "np.put(x, [0, 2], [-44, -55])\n",
    "x # array([-44,   2, -55,   4,   5])\n",
    "\n",
    "x = np.array([0,1,2,3,4,5])\n",
    "np.roll(x, 2)  #array([4, 5, 0, 1, 2, 3]) each element shift 2 position\n",
    "####################################\n",
    "import random\n",
    "\n",
    "np.random.seed(0)#the seed for the next random number\n",
    "random.seed(0)\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "np.random.randn() # 1.764052345967664 #Return a sample value from the “standard normal”distribution (mean 0 and variance )\n",
    "np.random.randn(2,2)\n",
    "#array([[ 1.76,  0.4 ],\n",
    "#       [ 0.98,  2.24]])\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "np.random.rand(2,2) # random samples from a uniform distribution over [0, 1)\n",
    "#array([[ 0.44,  0.89],\n",
    "#       [ 0.96,  0.38]])\n",
    "random.random()    #0.8462617713735385 #show a number between 0-1 uniform distribution #can return 0 but not 1\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "np.random.randint(0,4, size=(2,2)) #each value is 0, 1, 2 or 3\n",
    "#array([[2, 3],\n",
    "#       [3, 2]]\n",
    "random.randint(0,4)    #0  #0, 1, 2 or 3 \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "np.random.choice(5,3) #array([4, 2, 0]) show one value between 0, 1, 2, 3, 4\n",
    "np.random.choice(5,3,replace=False) # draw sample without replacement\n",
    "np.random.choice([1,2,4], 3) #array([1, 2, 2])\n",
    "random.choice([1,2,4])       # show 1, 2 , or 4\n",
    "\n",
    "import string\n",
    "A=string.ascii_uppercase  #'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "A=string.ascii_lowercase#'abcdefghijklmnopqrstuvwxyz'\n",
    "random.choice(A)          #'P'\n",
    "\n",
    "random.sample(range(5),3)   #[3, 0, 4] # from 0,1,2,3,4 choose 3 values\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "np.random.normal(loc=0,scale=1, size=(3,3)) #scale is std\n",
    "np.random.standard_normal(size=(3,3))    #Draw samples from a standard Normal distribution (mean=0, stdev=1).\n",
    "\n",
    "random.gauss(mu=0, sigma=1)               # 0.7764926257342503\n",
    "gaussiabsample=[random.gauss(mu=0, sigma=1) for i in range(100)]\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "np.random.exponential(scale=1.0, size=3) #Draw samples from an exponential distribution p(x)=(1/scale)exp(-x/scale)\n",
    "np.random.uniform(-1,1,size=(3,3)) #a uniform distribution from -1 and 1\n",
    "np.random.permutation(5) #array([4, 2, 0, 1, 3])\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "x=np.array([1,2,3,4])\n",
    "np.random.shuffle(x)\n",
    "random.shuffle(x)\n",
    "x #array([4, 1, 3, 2])\n",
    "####################################\n",
    "x = np.array([1,1,2])\n",
    "np.unique(x) #array([1, 2])\n",
    "\n",
    "x = np.array([[1,2,0],[0,4,5]])\n",
    "np.argsort(x, axis=0)# show the index from the smallest value to the largest\n",
    "#array([[1, 0, 0],\n",
    "#       [0, 1, 1]], dtype=int64)\n",
    "np.argmin(x, axis=0) #array([1, 0, 0], dtype=int64)\n",
    "np.argmax(x, axis=0) #array([0, 1, 1], dtype=int64)\n",
    "np.sort(x, axis=0) \n",
    "#array([[0, 2, 0],\n",
    "#       [1, 4, 5]]\n",
    "\n",
    "x = [1,2,2,3] \n",
    "y = [5,4,3,2] \n",
    "np.lexsort((y, x)) # Sort by x, then by y # list each element in x ranking (smallest =0), if the elements are the same, use y\n",
    "array([0, 2, 1, 3], dtype=int64)\n",
    "####################################\n",
    "x = np.array([220,330,4])\n",
    "bins = np.array([0,100,200,300])\n",
    "np.digitize(x, bins)   \n",
    "np.searchsorted(bins,x)\n",
    "#array([3, 4, 1], dtype=int64)\n",
    "np.searchsorted(bins, 110)  #2\n",
    "np.searchsorted(bins, 100, side='left')  #1\n",
    "np.histogram(x, bins)   #(array([1, 0, 1], dtype=int64), array([  0, 100, 200, 300]))=counts, bins\n",
    "\n",
    "import bisect\n",
    "A=[10,11,12,13,14]\n",
    "bisect.bisect(A, 12.5)          #3  #find which index that 12.5 should be inserted to\n",
    "bisect.insort(A,12.5)           #A become [10, 11, 12, 12.5, 13, 14]\n",
    "bisect.bisect_left(A, 12.5)     #3\n",
    "bisect.bisect_right(A, 12.5)    #4\n",
    "\n",
    "x = np.array([220,330,40])\n",
    "y = np.array([22,33,4])\n",
    "binx = np.array([0,100,200,300])\n",
    "biny = np.array([0,10,20,30])\n",
    "np.histogram2d(x, y, bins=(binx, biny))\n",
    "#(array([[ 1.,  0.,  0.],\n",
    "#        [ 0.,  0.,  0.],\n",
    "#        [ 0.,  0.,  1.]]),\n",
    "# array([   0.,  100.,  200.,  300.]),\n",
    "# array([  0.,  10.,  20.,  30.]))  =counts, binx, biny\n",
    "\n",
    "\n",
    "x=np.array([0, 1, 1, 3, 3])\n",
    "weight = np.array([0.1,0.2,0.3,0.4,0.5]) \n",
    "np.bincount(x)                     #array([1, 2, 0, 2], dtype=int64) Count number of occurrences of each value \n",
    "np.bincount(x,weight)              #array([ 0.1,  0.5,  0. ,  0.9])\n",
    "np.bincount(x, weight, minlength=7) #array([ 0.1,  0.5,  0. ,  0.9,  0. ,  0. ,  0. ])\n",
    "####################################\n",
    "x = np.array([[1,2,3],[4,5,6]])\n",
    "np.mean(x, axis=0)     #array([ 2.5,  3.5,  4.5])\n",
    "np.average(x, axis=0)  #array([ 2.5,  3.5,  4.5])\n",
    "np.median(x, axis=0)\n",
    "np.std(x, axis=0)\n",
    "np.var(x, axis=0)\n",
    "np.ptp(x, axis=0) # array([3, 3, 3]) return max-min\n",
    "np.sum(x, axis=0)\n",
    "np.min(x, axis=0)\n",
    "np.max(x, axis=0) \n",
    "np.diff(x, axis=0)  #array([[3, 3, 3]])\n",
    "np.prod(x, axis=0) #array([ 4, 10, 18])\n",
    "np.cumsum(x, axis=0)\n",
    "#array([[1, 2, 3],\n",
    "#       [5, 7, 9]])\n",
    "np.cumprod(x, axis=0) \n",
    "#array([[ 1,  2,  3],\n",
    "#       [ 4, 10, 18]])\n",
    "np.apply_along_axis(lambda x:(x[0] + x[-1]) * 0.5,  1, x) #array([ 2.,  5.]) # 1 means axis=1\n",
    "\n",
    "np.abs(x)\n",
    "#array([[1, 2, 3],\n",
    "#       [4, 5, 6]])\n",
    "np.sqrt(x)\n",
    "#array([[ 1.  ,  1.41,  1.73],\n",
    "#       [ 2.  ,  2.24,  2.45]]\n",
    "np.log(x)\n",
    "np.log1p(x) #return log(1+x)\n",
    "\n",
    "np.exp(x)\n",
    "from scipy import exp\n",
    "exp(x)\n",
    "\n",
    "from scipy.special import expit#expit(z)=1/(1+exp(-z))\n",
    "expit(x) #expit(x) = 1/(1+exp(-x)). \n",
    "\n",
    "np.expm1(x) #return exp(x)-1\n",
    "np.diag(x)  #array([1, 5])\n",
    "np.diag([1, 5]) \n",
    "#array([[1, 0],\n",
    "#       [0, 5]])\n",
    "\n",
    "x = np.array([[1,2,3],[4,5,6]])\n",
    "np.percentile(x, 50)         #3.5\n",
    "np.percentile(x, 50, axis=0) #array([ 2.5,  3.5,  4.5])\n",
    "np.percentile(x, [25,50,75], axis=0)\n",
    "#array([[ 1.75,  2.75,  3.75],\n",
    "#       [ 2.5 ,  3.5 ,  4.5 ],\n",
    "#       [ 3.25,  4.25,  5.25]])\n",
    "\n",
    "np.modf([2.7, 3.5]) #(array([ 0.7,  0.5]), array([ 2.,  3.]))\n",
    "np.maximum([2, 3, 4], [1, 5, 2]) #array([2, 5, 4])\n",
    "np.sign([-5., 4.5])  #array([-1.,  1.])\n",
    "np.floor([1.2,2.2,3.2]) #array([ 1.,  2.,  3.])\n",
    "\n",
    "import math\n",
    "math.ceil(2.3) #3\n",
    "math.sqrt(2)\n",
    "math.log(2)\n",
    "math.factorial(4) #4!=24\n",
    "####################################\n",
    "x = [1,2,3,4]\n",
    "y = [40,30,20,10]\n",
    "np.corrcoef(x,y)  #return the correlation coefficient matrix of the variables\n",
    "x = np.array([[1,2,3,4],[40,30,20,10]])\n",
    "np.corrcoef(x)\n",
    "#rray([[ 1., -1.],\n",
    "#      [-1.,  1.]])\n",
    "np.cov(x,y)      #return the covariance matrix of the variables\n",
    "x = np.array([[1,2,3,4],[40,30,20,10]])\n",
    "np.cov(x)\n",
    "#rray([[   1.67,  -16.67],\n",
    "#      [ -16.67,  166.67]])\n",
    "\n",
    "x = np.array([[1,0],[0,2]])\n",
    "#(1)\n",
    "eigenvalues, eigenvectors=np.linalg.eig(x)\n",
    "#(2)\n",
    "from scipy.linalg import eigh\n",
    "eigenvalues, eigenvectors=eigh(x)\n",
    "eigenvalues  #array([ 1.,  2.])\n",
    "eigenvectors \n",
    "#array([[ 1.,  0.],\n",
    "#       [ 0.,  1.]])\n",
    "np.linalg.inv(x)  # inverse of the matrix x\n",
    "#array([[ 1. ,  0. ],\n",
    "#       [ 0. ,  0.5]])\n",
    "\n",
    "x = np.array([3,4])\n",
    "np.linalg.norm(x)  #5\n",
    "x = np.array([[3,0],[0,4]])\n",
    "np.linalg.norm(x)  #5.0 # sqrt(3^2 +0+0+4^2)\n",
    "np.linalg.norm(x,axis=0) #array([ 3.,  4.])  # (sqrt(3^2+0), sqrt(4^2+0))\n",
    "\n",
    "x = np.array([10,20])\n",
    "y = np.array([[1,2],\n",
    "              [3,4]])\n",
    "np.dot(x,y) \n",
    "x.T.dot(y)\n",
    "#array([ 70, 100])\n",
    "\n",
    "x = np.array([[1,2],[3,4]])\n",
    "np.matrix(x)\n",
    "#matrix([[1, 2],\n",
    "#        [3, 4]])\n",
    "np.matrix(x).T    #transpose matrix\n",
    "#matrix([[1, 3],\n",
    "#        [2, 4]])\n",
    "np.matrix(x).I    #inverse matrix\n",
    "#matrix([[-2. ,  1. ],\n",
    "#        [ 1.5, -0.5]])\n",
    "####################################\n",
    "x = np.array([1,2])\n",
    "y= np.array([3,4])\n",
    "np.save('filename.npy', x)\n",
    "np.load('filename.npy')\n",
    "\n",
    "np.savetxt('filename.txt',x)\n",
    "np.loadtxt('filename.txt')\n",
    "\n",
    "np.save('filename.npz', ,a=x, b=y)\n",
    "data=np.load('filename.npz') \n",
    "data['a'] #is x\n",
    "\n",
    "y=x.copy()\n",
    "####################################\n",
    "x = np.array([1, 2, 2.5])\n",
    "x.astype(int)   #array([1, 2, 2])\n",
    "x.astype(float) #array([ 1. ,  2. ,  2.5])\n",
    "x.astype(str)   #array(['1.0', '2.0', '2.5'])\n",
    "x.dtype         #dtype('float64'\n",
    "x.all()         #True #ask all true\n",
    "x.any()         #True #ask any true\n",
    "x.ndim          #1\n",
    "x.shape         #(3L,)\n",
    "\n",
    "x.shape[0]\n",
    "len(x)          \n",
    "#3\n",
    "####################################\n",
    "x=np.array([[1,2],[3,4],[5,6],[7,8]])\n",
    "x[::2]# take every other row\n",
    "#array([[1, 2],\n",
    "#       [5, 6]])\n",
    "x[::-1]#row sequence flip\n",
    "#array([[7, 8],\n",
    "#       [5, 6],\n",
    "#       [3, 4],\n",
    "#       [1, 2]])\n",
    "x[:-1]#delete the last row\n",
    "#array([[1, 2],\n",
    "#       [3, 4],\n",
    "#       [5, 6]])\n",
    "x[0,1] #2\n",
    "\n",
    "x=[1,2,3]\n",
    "x[::-1]# return [3,2,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Built-in Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1, 2, 3]\n",
    "y = [4, 5, 6]\n",
    "zipped = zip(x, y)\n",
    "zipped  #[(1, 4), (2, 5), (3, 6)]\n",
    "a,b=zip(*zipped) #[(1, 2, 3), (4, 5, 6)]=a,b , a=(1,2,3)\n",
    "\n",
    "x = ['A', 'B']\n",
    "list(enumerate(x)) #[(0, 'A'), (1, 'B')]\n",
    "list(enumerate(x, start=1)) #[(1, 'A'), (2, 'B')]\n",
    "\n",
    "dict(one=1, two=2, three=3)  #{'one': 1, 'three': 3, 'two': 2}\n",
    "dict(zip(['one', 'two', 'three'], [1, 2, 3]))\n",
    "dict([('two', 2), ('one', 1), ('three', 3)])\n",
    "dict({'three': 3, 'one': 1, 'two': 2})\n",
    "#{'one': 1, 'three': 3, 'two': 2}\n",
    "####################################\n",
    "x=[1,3,2,4]\n",
    "sorted(x)  #[1, 2, 3, 4]\n",
    "sorted(x, reverse=True) #[4, 3, 2, 1]\n",
    "#x=[[1,6,5],[2,3,10]]\n",
    "sorted(x, key=lambda x: x[1]) #[[2, 3, 10], [1, 6, 5]]\n",
    "sorted(['aaa','caa','baa'])  #['aaa', 'baa', 'caa']\n",
    "sorted('ccaab')              #['a', 'a', 'b', 'c', 'c']\n",
    "sorted(set('ccaab'))         #['a', 'b', 'c']\n",
    "\n",
    "x=[1,3,2,4]\n",
    "from random import random\n",
    "sorted(x, key=lambda x: random()) #[1, 4, 3, 2] \n",
    "import random\n",
    "random.shuffle(x)\n",
    "x # [3, 2, 4, 1]\n",
    "\n",
    "x=[1,3,2,4]\n",
    "x.sort()\n",
    "x # = [1, 2, 3, 4]\n",
    "\n",
    "x = ['ab','bbb','b']\n",
    "x.sort()\n",
    "x # = ['ab', 'b', 'bbb']\n",
    "x.sort(key=len)\n",
    "x  # = ['b', 'ab', 'bbb'] \n",
    "x.sort(key=lambda x: len(set(list(x))))\n",
    "x  # = ['b', 'bbb', 'ab']\n",
    "\n",
    "list(reversed([1,4,5,2])) #[2, 5, 4, 1]\n",
    "####################################\n",
    "range(5) #[0, 1, 2, 3, 4]\n",
    "\n",
    "x=[1,2,3]\n",
    "sum(x)  #6\n",
    "min(x)  #1\n",
    "max(x)  #3\n",
    "x=['aaa','b','cc']\n",
    "max(x,key=len)  #'aaa'\n",
    "\n",
    "7/3 #2.3333333333333335\n",
    "7//3 #2\n",
    "####################################\n",
    "set([1,3,2,2])  #{1, 2, 3}\n",
    "x = set([\"a\",\"a\"])\n",
    "y = set([\"a\",\"b\"])\n",
    "z = set([\"a\",\"c\"])\n",
    "f=(x,y,z) #f=({'a'}, {'a', 'b'}, {'a', 'c'})\n",
    "set.intersection(*f)  #{'a'}\n",
    "set.union(*f)         #{'a', 'b', 'c'}\n",
    "\n",
    "{0, 1, 2}.issuperset({0, 1})   #True\n",
    "{0, 1}.issubset({0, 1, 2})     #True\n",
    "{0, 1, 2}.isdisjoint({3,4})    #True #see if these two sets have no elements in common\n",
    "{0, 1}.union({0, 2, 5})#{0, 1, 2, 5} \n",
    "{0, 1}|{0, 2, 5}\n",
    "{0, 1}.intersection({0, 2, 5})#{0} \n",
    "{0, 1}&{0, 2, 5}\n",
    "{0, 1, 6}.difference({0, 2, 5})#{1, 6}\n",
    "{0, 1, 6}-{0, 2, 5}\n",
    "{0, 1, 6}.symmetric_difference({0, 2, 5})#{1, 2, 5, 6}     \n",
    "{0, 1, 6}^{0, 2, 5}\n",
    "\n",
    "frozenset([1,3,2,2])  #frozenset({1, 2, 3})\n",
    "frozenset([1,2])|frozenset([1,3]) #frozenset({1,2,3})\n",
    "frozenset([1,2])-frozenset([1,3]) #frozenset({2})\n",
    "frozenset([1,2])&frozenset([1,3]) #frozenset({1})\n",
    "frozenset([1,2])^frozenset([1,3]) #frozenset({2, 3})\n",
    "\n",
    "0|0 #0\n",
    "0|1 #1\n",
    "1|1 #1\n",
    "####################################\n",
    "list('abc')  #['a', 'b', 'c']\n",
    "tuple('abc') #('a', 'b', 'c')\n",
    "x=tuple([1,2,3]) #'tuple' object does not support item assignment\n",
    "x #(1, 2, 3)\n",
    "x[0] #1\n",
    "\n",
    "float(2) #show 2.0\n",
    "int(2.3) #show 2\n",
    "type(2)# show int\n",
    "str(a)#'a'\n",
    "bool()#(0),([]),(') return False #('a'),(1) return True\n",
    "\n",
    "####################################\n",
    "x={'a':1, 'b':2}\n",
    "x.keys()   #['a', 'b']\n",
    "x.values() #[1, 2]\n",
    "x.items()  #[('a', 1), ('b', 2)]\n",
    "x.get('a') # 1 \n",
    "x.update({'c':3})\n",
    "x['c'] = 3\n",
    "x  # = {'a': 1, 'b': 2, 'c': 3}\n",
    "del x['c']  #remove 'c': 3\n",
    "'a' in x #True\n",
    "list(iter(x))     \n",
    "list(x.iterkeys())\n",
    "#['a', 'b']\n",
    "\n",
    "from collections import defaultdict\n",
    "A=defaultdict(list) \n",
    "A['a'].append(1)  \n",
    "A  #defaultdict(list, {'a': [1]})\n",
    "A.items()#[('a', [1])]\n",
    "\n",
    "#can used to tuple too , ie.(123, 'xyz','xyz')\n",
    "C = [123, 'xyz','xyz'];\n",
    "C.count('xyz') # 2\n",
    "C.append([4, 5])# show [123, 'xyzxyz', 2009, [4, 5]]\n",
    "C.append(4);C# show [123, 'xyzxyz', 2009, 4]\n",
    "C.extend([4, 5, (1,2)])# C show [[123, 'xyz', 'xyz', 4, 5, (1, 2)]\n",
    "C.insert(1, 'H1')#C become [123, 'H1', 'xyz', 'xyz'] insert 'HI' to index1\n",
    "C.pop(1)\n",
    "C.remove('xyz')\n",
    "# C become [123, 'xyz']  remove the index 1\n",
    "####################################\n",
    "B='an book#pen'\n",
    "B.replace('an','a') #show a book#pen\n",
    "B.find('book')#3 show book the starting index# if B doesn't have book, it shows -1\n",
    "B.startswith('an') #show True\n",
    "B.split('#')# show ['an book', 'pen']#separate each token with #   #or (',')\n",
    "B.split()# show ['an', 'book#pen']\n",
    "B.isupper() #False #if B='BOOK', it will be True\n",
    "'an' in B #True\n",
    "B.index('b')#3\n",
    "B.count('o')#2\n",
    "B.upper()#'AN BOOK#PEN'\n",
    "\n",
    "A='3';A.isdigit() #True\n",
    "A='a';A.isdigit() #False\n",
    "A='aa';A.isalpha() #True\n",
    "\n",
    "x = ['a', 'b','c'];\n",
    "'::'.join(x)   #'a::b::c'\n",
    "x=' bc'\n",
    "x.strip()      #'bc' #delete space\n",
    "x='abc'\n",
    "x[::-1]        #'cba'\n",
    "####################################\n",
    "def f(x):\n",
    "    return x*2\n",
    "f(4)#8\n",
    "S=lambda x: x*2\n",
    "S(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]\n",
    "d = defaultdict(list)\n",
    "for k, v in s:\n",
    "    d[k].append(v)\n",
    "d  #defaultdict(list, {'blue': [2, 4], 'red': [1], 'yellow': [1, 3]})\n",
    "###############\n",
    "for _ in range(2):\n",
    "for i in range(2):\n",
    "for _ in xrange(200):#for very long range, recommand use xrange\n",
    "    \n",
    "for i in range(3):\n",
    "    print i*i\n",
    "#0\n",
    "#1\n",
    "#4\n",
    "[x*x for x in range(3)] # [0, 1, 4]\n",
    "###############    \n",
    "x = ['A', 'B']\n",
    "for i,j in enumerate(x):\n",
    "    print i,j\n",
    "#0 A\n",
    "#1 B\n",
    "\n",
    "x = [0, 1]\n",
    "y = ['A', 'B']\n",
    "for i, j in zip(x,y):\n",
    "    print i,j\n",
    "#0 A\n",
    "#1 B \n",
    "\n",
    "x = np.array([[0,1],['A','B']])\n",
    "for i in zip(*x):\n",
    "    print i\n",
    "#('0', 'A')\n",
    "#('1', 'B'\n",
    "x=[(1, 4), (2, 5), (3, 6)]\n",
    "for i in zip(*x):\n",
    "    print i\n",
    "#(1, 2, 3)\n",
    "#(4, 5, 6)  \n",
    "###############\n",
    "from itertools import combinations\n",
    "for i in combinations([0,1,2], r=2):\n",
    "    print i\n",
    "#(0, 1)\n",
    "#(0, 2)\n",
    "#(1, 2)\n",
    "###############\n",
    "from itertools import product \n",
    "for i in product([0,1],[0,1]):\n",
    "    print i\n",
    "#(0, 0)\n",
    "#(0, 1)\n",
    "#(1, 0)\n",
    "#(1, 1)\n",
    "###############\n",
    "import itertools\n",
    "A=lambda x:x[0]\n",
    "B=['abb', 'add', 'baa']\n",
    "for i, j in itertools.groupby(B,A):\n",
    "    print i, list(j)\n",
    "#a ['abb', 'add']\n",
    "#b ['baa']\n",
    "###############\n",
    "x={'a':1, 'b':2}\n",
    "for i, j in x.items():\n",
    "    print i, j\n",
    "#a 1\n",
    "#b 2\n",
    "###############\n",
    "df=DataFrame(['a','b'], columns=['A'])\n",
    "for i, j in df['A'].iteritems():\n",
    "    print i, j\n",
    "#0 a\n",
    "#1 b\n",
    "###############\n",
    "if true:\n",
    "    ...\n",
    "elif true:\n",
    "    ...\n",
    "else:\n",
    "    ...\n",
    "    \n",
    "if true or true\n",
    "###############\n",
    "for i in [1,2,3]:\n",
    "    if i ==2:\n",
    "        break #when i=2, stop for loop\n",
    "    print i\n",
    "#1\n",
    "\n",
    "for i in [1,2,3]:\n",
    "    if i ==2:\n",
    "        continue#skip i=2 loop\n",
    "    print i\n",
    "#1\n",
    "#3\n",
    "\n",
    "while x > 0:\n",
    "    if i > 5:\n",
    "        break\n",
    "    i +=1\n",
    "    print i\n",
    "#1\n",
    "#2\n",
    "#3\n",
    "#4\n",
    "#5\n",
    "#6\n",
    "###############\n",
    "A=[(1,2),(3,4)]\n",
    "for i in A:\n",
    "    for x in i:\n",
    "        if x !=4:\n",
    "            print x\n",
    "#1\n",
    "#2\n",
    "#3\n",
    "B=[x for i in A for x in i if x != 4]\n",
    "B  #=[1, 2, 3]\n",
    "###############\n",
    "#fill a list value into a histogram\n",
    "A={}\n",
    "for i in [1,1,2,3,3]:\n",
    "    A[i]=A.get(i,0) +1\n",
    "\n",
    "from collections import Counter\n",
    "A=Counter([1,1,2,3,3])\n",
    "\n",
    "A  #= {1: 2, 2: 1, 3: 2}\n",
    "###############\n",
    "# A generator do not store all the values in memory, they generate the values on the fly.\n",
    "# Yield is a keyword that is used like return, except the function will return a generator\n",
    "def f():\n",
    "    for i in range(3):\n",
    "        yield i**2\n",
    "        \n",
    "F=f()# F is <generator object f at 0x000000000EC21900>\n",
    "for i in F:\n",
    "    print(i)\n",
    "#0\n",
    "#1\n",
    "#4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expression operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "A='a b\\t    c\\t'\n",
    "re.split('\\s+',A)#['a', 'b', 'c', '']#seperate with more than one space\n",
    "re.split('\\s',A) #['a', 'b', '', '', '', '', 'c', '']\n",
    "re.compile('\\s+').split(A)#['a', 'b', 'c', '']#seperate with more than one space\n",
    "re.compile('\\s+').findall(A)#[' ', '\\t    ', '\\t']\n",
    "############################################################################\n",
    "B='lin10._%+-@yahoo.com, lin10@yahoo.com '\n",
    "patten=r'[A-Z0-9._%+-]+@[A-z0-9]+.[A-z]{2,4}'\n",
    "re.compile(patten, flags=re.IGNORECASE).findall(B)     # ['lin10._%+-@yahoo.com', 'lin10@yahoo.com']\n",
    "#search the first email\n",
    "f=re.compile(patten, flags=re.IGNORECASE).search(B)\n",
    "B[f.start():f.end()]                                   #'lin10._%+-@yahoo.com' \n",
    "#replace email address with 'email'\n",
    "re.compile(patten, flags=re.IGNORECASE).sub('email', B)#email, email \n",
    "############################################################################\n",
    "patten1=r'([A-Z0-9._%+-]+)@([A-z0-9]+).([A-z]{2,4})'\n",
    "re.compile(patten1, flags=re.IGNORECASE).findall(B)#[('lin10._%+-', 'yahoo', 'com'), ('lin10', 'yahoo', 'com')]\n",
    "re.compile(patten1, flags=re.IGNORECASE).sub(r'X:\\1,Y:\\2,Z:\\3',B)#'X:lin10._%+-,Y:yahoo,Z:com, X:lin10,Y:yahoo,Z:com '\n",
    "#(r' \\1 \\2 \\3',B)\n",
    "\n",
    "A=DataFrame(['lin10@yahoo.com'], columns=['B'])\n",
    "A['B'].str[:5]#0    lin10\n",
    "A['B'].str.findall(patten1, flags=re.IGNORECASE)\n",
    "#0    [(lin10, yahoo, com)]\n",
    "#Name: B, dtype: object\n",
    "A['B'].str.match(patten1, flags=re.IGNORECASE) \n",
    "#0    (lin10, yahoo, com)\n",
    "#Name: B, dtype: object\n",
    "A['B'].str.match(patten1, flags=re.IGNORECASE).str.get(1)  \n",
    "#0    yahoo\n",
    "#Name: B, dtype: object\n",
    "############################################################################\n",
    "patten2=r'(?P<X>[A-Z0-9._%+-]+)@(?P<Y>[A-z0-9]+).(?P<Z>[A-z]{2,4})'\n",
    "f1=re.compile(patten2, flags=re.IGNORECASE)\n",
    "f2=f1.match('wesm@yahoo.com')\n",
    "f2.groupdict()#{'X': 'wesm', 'Y': 'yahoo', 'Z': 'com'}\n",
    "#\\s any whitespace character, includes ' ', \\t, \\n(newline), \\r\n",
    "#[] Used to indicate a set of characters, In a set:\n",
    "# [a-z] means any lowercase letter; [0-9] means any number\n",
    "#special characters lose their special meaning inside [].\n",
    "# [._%+-] will match any of the literal characters '.', '_', '%', '+', '-'\n",
    "\n",
    "# . mean  any character except a newline\n",
    "# ^ mean the start of the string\n",
    "# $ mean the end of the string or just before the newline at the end of the string\n",
    "# *  match 0 or more repetitions \n",
    "# + match 1 or more repetitions \n",
    "# ? match 0 or 1 repetitions \n",
    "# {m} exactly m copies, ex: a{6} will match exactly six 'a' characters\n",
    "#{m,n} match from m to n repetitions , ex: a{3,5} will match from 3 to 5 'a' characters.\n",
    "# {m,n}? \n",
    "#(...) Matches whatever regular expression is inside the parentheses\n",
    "#(?P<name>...) assign a group name\n",
    "############################################################################\n",
    "A=DataFrame(['aaa bbb 6p 480kg BIM 41'], columns=['B'])\n",
    "#s(Series) can use like A'B] too\n",
    "A['B'].str.extract('(\\D*)', expand=False) \n",
    "#0    aaa bbb \n",
    "#Name: B, dtype: object \n",
    "A['B'].str.extract('(\\D*)', expand=True) #return a table\n",
    "#      0\n",
    "#0  aaa bbb\n",
    "A['B'].str.extract('.+\\s(\\D*) \\d+$', expand=False)\n",
    "#0    BIM\n",
    "#Name: B, dtype: object\n",
    "A['B'].str.extract('(\\d+)p', expand=False)\n",
    "#0    6\n",
    "#Name: B, dtype: object\n",
    "A['B'].str.extract('(\\d+)(kg|g)', expand=False) #return a table\n",
    "#    0  1\n",
    "#0  480 kg\n",
    "A['B'].map(lambda x: '_'.join([i for i in x.lower().split()]))\n",
    "#0    aaa_bbb_6p_480kg_bim_41\n",
    "#Name: B, dtype: object\n",
    "A['B'].map(lambda x: ' '.join([i for i in x.lower().split()]))\n",
    "#0    aaa bbb 6p 480kg bim 41\n",
    "#Name: B, dtype: object \n",
    "A['B'].str.split(' ')\n",
    "#0    [aaa, bbb, 6p, 480kg, BIM, 41]\n",
    "#Name: B, dtype: object\n",
    "A['B'].str.split(' ').str[0]\n",
    "#0    aaa\n",
    "#Name: B, dtype: object\n",
    "A['B'].str.contains('p')\n",
    "#0    True\n",
    "#Name: B, dtype: bool\n",
    "\n",
    "#() group together and show up\n",
    "#*  0 or more\n",
    "#+  more than 1\n",
    "#\\D  non digit characters\n",
    "#\\s space\n",
    "#\\d digit number\n",
    "#. any character except new line\n",
    "# $ the end of the string\n",
    "# | or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print '%.2f' % (2.3333)        #2.33\n",
    "print '%s' % ('sd')            #sd\n",
    "print '%10s' % ('sd')          #        sd # 10 spaces and sd \n",
    "print '%r' % ({'sd':1,'ee':2}) #{'ee': 2, 'sd': 1}\n",
    "print'_%03d' % 3               #_003\n",
    "print'%i' % 3.333              #3\n",
    "print'%d' % 3.333              #3\n",
    "\n",
    "print '{} {}'.format('one', 1)              #one 1\n",
    "print '{:>10}'.format('test')               #      test# (align right)\n",
    "print '{:10}'.format('test')                #test      #(align left)\n",
    "print '{:_<10}'.format('test')              #test______\n",
    "print '{:_>10}'.format('test')              #______test\n",
    "print '{:^10}'.format('test')               #   test   #(align center)\n",
    "print '{:.5}'.format('xylophone')           #xylop\n",
    "print '{:10.5}'.format('xylophone')         #xylop     #(align left)\n",
    "print '{:d}'.format(42)                     #42   #format number in integer\n",
    "print '{:f}'.format(3.14159265358)          #3.141593#float\n",
    "print '{:.3f}'.format(3.14159265358)        #3.142\n",
    "print '%.2f' % (2.3333)                     #2.33\n",
    "print ('%.2f' % (2.3333)).rjust(8)          #   2.33    #8 length string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#'test.csv'\n",
    "#   A   B\n",
    "#0  1  10\n",
    "#1  2  20\n",
    "with open ('test.csv','r') as f: \n",
    "    B=f.read()  #'A,B\\n1,10\\n2,20\\n'\n",
    "    \n",
    "list(open('test.txt'))#('xx.stdout')\n",
    "#['A\\tB\\n', '1\\t10\\n', '2\\t20\\n']\n",
    "####################################\n",
    "import csv\n",
    "with open('test.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print row\n",
    "#['A', 'B']\n",
    "#['1', '10']\n",
    "#['2', '20']\n",
    "####################################\n",
    "x=[]\n",
    "with open ('test.csv', 'rb') as f:\n",
    "    A=csv.reader(f)\n",
    "    row=A.next()\n",
    "    featurename=np.array(row) #array(['A', 'B']\n",
    "    for i in A:\n",
    "        x.append(i)\n",
    "x=np.array(x) \n",
    "x #array([['1', '10'],\n",
    "  #       ['2', '20']], \n",
    "####################################\n",
    "f=open('test.csv')\n",
    "reader=csv.reader(f)\n",
    "for line in reader:\n",
    "    print line\n",
    "#['A', 'B']\n",
    "#['1', '10']\n",
    "#['2', '20']\n",
    "lines=list(reader)\n",
    "header, values=lines[0], lines[1:]\n",
    "data_dict={columnname: columnvalues for columnname, columnvalues in zip(header, zip(*values))}\n",
    "data_dict #{'A': ('1', '2'), 'B': ('10', '20')}\n",
    "\n",
    "f=open('test.txt')\n",
    "lines=f.readlines()\n",
    "for i in lines:\n",
    "    A=i.strip().split('\\t') #if i is 'ap\\t bo\\t la\\n', show ['ap',' bo','la'] #strip() delete line terminator \\n\n",
    "    print A\n",
    "#['A', 'B']\n",
    "#['1', '10']\n",
    "#['2', '20']\n",
    "\n",
    "###################################\n",
    "df=pd.read_csv('.csv', sep=',', delimiter=None, header='infer'(None), usecols=['column1name','column2name'], \n",
    "index_col='column1name',prefix=None,dtype=None\n",
    "skiprows=[0,2], nrows=5, na_values=['NuLL'],chunksize=1000, parse_date=True)\n",
    "\n",
    "#sep=',' or '\\s+'(separate with a space) or'\\t' separate with a tab\n",
    "#index_col=#0, the first column become index#index_col='column1name', the unique values of column1 become the index level\n",
    "#usecols= [0, 1, 2] or [‘foo’, ‘bar’, ‘baz’]#pick the selected column\n",
    "#header=None show no column names\n",
    "#skiprows=[0,2] skip the first and third rows\n",
    "#na_values=['NuLL'], if any missing value, mark it as NaN\n",
    "#parse_date=True : date format become 1990-02-01, and date column become index \n",
    "#nrows=5 only show the first 5 rows\n",
    "#if reading a csv file has momery difficulty, need to define chuncksize, and then:\n",
    "df2 = pd.concat([chunk for chunk in df])\n",
    "\n",
    "df=pd.read_table('test.csv', sep=',')\n",
    "Series.from_csv('test.csv')\n",
    "#A     B\n",
    "#1    10\n",
    "#2    20\n",
    "#dtype: object\n",
    "\n",
    "data=pd.ExcelFile('test.xlsx')\n",
    "f=data.parse('test') #see the data in the first sheet 'test'\n",
    "#   A  B\n",
    "#0  1 10\n",
    "#1  2 20\n",
    "###################################\n",
    "#if f=imag001-0016.png\n",
    "f[3:f.index('-')] #will show 001\n",
    "###################################\n",
    "import json\n",
    "json_data = open(\"file name\")\n",
    "data = json.load(json_data)\n",
    "df=DataFrame(data)\n",
    "###################################\n",
    "import gzip\n",
    "f = gzip.open('file.txt.gz', 'rb')\n",
    "file_content = f.read()\n",
    "\n",
    "with gzip.open('file.txt.gz','r') as f:\n",
    "    for line in f: \n",
    "        print('got line', line)\n",
    "        \n",
    "from gzip import GzipFile\n",
    "data=[k for k in A.split() for A in GzipFile('file.txt.gz')]\n",
    "###################################\n",
    "from io import StringIO\n",
    "X=''' A, B\n",
    "      1, 10\n",
    "      2, 20'''\n",
    "X=unicode(X)\n",
    "pd.read_csv(StringIO(X)) # become a table\n",
    "#  A   B\n",
    "#0 1  10\n",
    "#1 2  20\n",
    "###################################\n",
    "import glob\n",
    "for i in glob.glob('C:\\Python27\\Scripts\\Anaconda2/*.txt'):\n",
    "          print i\n",
    "#C:\\Python27\\Scripts\\Anaconda2\\SentiWordNet_3.0.0_20130122.txt\n",
    "#C:\\Python27\\Scripts\\Anaconda2\\test.txt\n",
    "filelist=glob.glob('C:\\Python27\\Scripts\\Anaconda2/*.txt')\n",
    "filelist\n",
    "#['C:\\\\Python27\\\\Scripts\\\\Anaconda2\\\\SentiWordNet_3.0.0_20130122.txt',\n",
    "# 'C:\\\\Python27\\\\Scripts\\\\Anaconda2\\\\test.txt']\n",
    "###################################\n",
    "import os\n",
    "for dir_path, dir_name, files in os.walk('train/'):\n",
    "    for f in files:\n",
    "    #for f in files if f.endswith('.png')\n",
    "        image=os.path.join(dir_path, f) \n",
    "        A=mh.imread(image)\n",
    "###################################        \n",
    "import os\n",
    "path='C:\\Python27\\Scripts\\Anaconda2'\n",
    "filename= 'test.csv'\n",
    "os.path.join(path,filename) \n",
    "os.path.abspath(path+'/'+filename)\n",
    "#'C:\\\\Python27\\\\Scripts\\\\Anaconda2\\\\test.csv'\n",
    "\n",
    "os.listdir(path)            # list all files in that directory\n",
    "os.chdir(path)              # go to one directory\n",
    "os.path.dirname(path)       #'C:\\\\Python27\\\\Scripts'    #Return the directory name of pathname path\n",
    "os.path.exists(filename)    #True         #This file is existed in the current diectory\n",
    "os.getcwd()                 #'C:\\\\Python27\\\\Scripts\\\\Anaconda2'  # current directory\n",
    "os.path.splitext('C:\\\\Python27\\\\Scripts\\\\Anaconda2\\\\test.csv') #('C:\\\\Python27\\\\Scripts\\\\Anaconda2\\\\test', '.csv')\n",
    "os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    ['Dan', 42],\n",
    "    ['Cordelia', 33]\n",
    "]\n",
    "import csv\n",
    "with open('test.csv', 'w') as outfile:\n",
    "    mywriter = csv.writer(outfile, lineterminator='\\n')\n",
    "    mywriter.writerow(['name', 'age']) #add header\n",
    "    for d in data:\n",
    "        mywriter.writerow(d)\n",
    "# test.csv become\n",
    "#   name     age\n",
    "#0  Dan      42\n",
    "#1 Cordelia  33\n",
    "#########JSON data (JAVASCRIPT object notation)\n",
    "data={'column1name':[1,2],'column2name':[3,4]}\n",
    "import json\n",
    "json_data=json.dump(data)\n",
    "##############################################\n",
    "# Save very large data array on disk as an in-memory array\n",
    "data = np.arange(4, dtype='float32').reshape(2,2)\n",
    "mmap=np.memmap('filename', dtype='float64', mode='w+', shape=(2,2))\n",
    "mmap[:] = data[:]\n",
    "mmap.flush()\n",
    "del mmap\n",
    "# Open an existing memory map\n",
    "mmap=np.memmap('filename',mode='r', dtype='float64', shape=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(nrows=1,ncols=1, figsize=(5,5), facecolor='white',sharex=True, sharey=True)\n",
    "x=[1,2,3,4]\n",
    "y=[1,4,9,16]\n",
    "ax.plot(x,y, ls='--',lw=1,marker='.',alpha=0.8,label='data',color='k');\n",
    "#aipha=(1: darkest),\n",
    "#drawstyle='step-post',\n",
    "#hold=True ( for adding more plots on the same graph),   \n",
    "#color='k'(black),‘b’(blue),‘g’(green),‘r’(red),‘c’(cyan),‘m’(magenta),‘y’(yellow),‘w’(white)\n",
    "#marker=”.”(point),“o”(circle),“v”(triangle_down),“^”(triangle_up),“<”(triangle_left),“>”(triangle_right),“8”(octagon)\n",
    "#,“s”(square),“p”(pentagon),“*”(star),“D”(diamond)\n",
    "plt.plot(x, y, drawstyle='steps-post') #drawstyle='steps-mid', 'steps-pre', 'steps-post' #step function\n",
    "ax.semilogx(x,y); #a plot with log scaling on the x axis.\n",
    "ax.semilogy(x,y); #a plot with log scaling on the y axis.\n",
    "ax.scatter(x,y);\n",
    "ax.scatter(x,y, c=x,cmap=plt.get_cmap('RdBu')) # scatter points have different colors\n",
    "#cmap=plt.cm.RdYlGn,plt.cm.Blues,cmap=plt.cm.BrBG,cmap=plt.cm.Greens,plt.cm.RdGy,plt.cm.YlOrRd,plt.cm.autumn,plt.cm.binary,plt.cm.gist_earth,\n",
    "#plt.cm.gist_heat,plt.cm.hot,plt.cm.spring,plt.cm.summer,plt.cm.jet,plt.cm.Spectral_r\n",
    "ax.axvline(x=2,ymin=0.58, ymax = 0.79, color='r', linestyle='--', lw=2) # draw a vertical line\n",
    "ax.hlines(y=2, xmin=-10, xmax=50, lw=2); # draw a horizontal line\n",
    "ax.set_xticks([0,10,20,30]);\n",
    "ax.set_yticks([0,10,20,30]);\n",
    "ax.set_xticklabels(['a','b','c','d'], rotation=90, fontsize=10);\n",
    "ax.set_yticklabels\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(0,100)\n",
    "ax.set_ylim(0,100)\n",
    "ax.axis([0, 100, 0, 50]) # xlim=(0,100), ylim=(0,50)\n",
    "ax.set_xlabel('xlabel')\n",
    "ax.set_ylabel('ylabel')\n",
    "ax.set_title('This is the title', fontsize='large')\n",
    "ax.legend(loc='best')\n",
    "#‘upper right’,‘upper center’,‘upper left’,‘lower left’,‘lower center’,‘lower right’,\n",
    "#‘center’,‘center left’,‘center right’,‘right’,\n",
    "ax.grid(True)\n",
    "ax.text(2.5, 2, r'$\\mu=100,\\ \\sigma=15$', bbox=dict(facecolor='red', alpha=0.5), fontsize=12) #(xposition, yposition\n",
    "ax.annotate('local max', xy=(2, 3), xytext=(3, 1.5),  #add arrow and text to a data point \n",
    "             arrowprops=dict(facecolor='black', shrink=0.05)) \n",
    "#xytext is the text location(xposition,yposition)\n",
    "#xy is the arrow final point location(xposition,yposition)\n",
    "\n",
    "# delete all edges\n",
    "for i in ax.spines.values():\n",
    "    i.set_visible(False)\n",
    "\n",
    "# set the xtick format\n",
    "for tick in ax.xaxis.get_ticklabels():\n",
    "    tick.set_fontsize('large')\n",
    "    tick.set_fontname('Times New Roman')\n",
    "    tick.set_color('blue')\n",
    "    tick.set_weight('bold')\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "# Close the figure \n",
    "plt.close(fig) #plt.close('all')\n",
    "######################  bar #######################################\n",
    "objects = ('A', 'B', 'C')\n",
    "y_pos = np.arange(len(objects))\n",
    "x = [10,8,6]\n",
    "ax.bar(y_pos, x, align='center', alpha=0.5,height=0.4, color='g',label='data')\n",
    "ax.set_xticks(y_pos);\n",
    "ax.set_xticklabels(objects);\n",
    "\n",
    "ax.barh(y_pos, x, align='center', alpha=0.5,height=0.4, color='g',label='data')\n",
    "ax.set_yticks(y_pos);\n",
    "ax.set_yticklabels(objects);\n",
    "\n",
    "df = pd.DataFrame([[5,10],[10,20],[5,9]])\n",
    "df.plot(kind='bar',ax=ax, stacked=True)\n",
    "######################  boxplot ######################################\n",
    "x1 = np.random.normal(0,1,50)\n",
    "x2 = np.random.normal(1,1,50)\n",
    "x3 = np.random.normal(2,1,50)\n",
    "bp = ax.boxplot([x1,x2,x3], patch_artist=True)\n",
    "for box in bp['boxes']:\n",
    "    # change outline color\n",
    "    box.set( color='#7570b3', linewidth=2)\n",
    "    # change fill color\n",
    "    box.set( facecolor = '#1b9e77' )\n",
    "\n",
    "## change color and linewidth of the whiskers\n",
    "for whisker in bp['whiskers']:\n",
    "    whisker.set(color='#7570b3', linewidth=2)\n",
    "\n",
    "## change color and linewidth of the caps\n",
    "for cap in bp['caps']:\n",
    "    cap.set(color='#7570b3', linewidth=2)\n",
    "\n",
    "## change color and linewidth of the medians\n",
    "for median in bp['medians']:\n",
    "    median.set(color='#b2df8a', linewidth=2)\n",
    "\n",
    "## change the style of fliers and their fill\n",
    "for flier in bp['fliers']:\n",
    "    flier.set(marker='o', color='#e7298a', alpha=0.5)\n",
    "    \n",
    "ax.set_xticklabels(['Sample1', 'Sample2', 'Sample3'])\n",
    "####################   hist   #######################################\n",
    "x = np.random.randn(1000)\n",
    "bins = np.linspace(-5, 5, 50)\n",
    "ax.hist(x, bins, alpha=0.5,normed=1);\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(100), columns=['A'])\n",
    "df['A'].plot(kind='hist', ax=ax)\n",
    "df['A'].plot(kind='kde', ax=ax, secondary_y=True) #kernel density estimate\n",
    "#######################  pie #########################################\n",
    "labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n",
    "sizes = [15, 30, 45, 10]  # proportion\n",
    "explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "ax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "###################### contourf  ######################################\n",
    "xlist = np.linspace(-3.0, 3.0, 100)\n",
    "ylist = np.linspace(-3.0, 3.0, 100)\n",
    "X, Y = np.meshgrid(xlist, ylist)\n",
    "Z = np.sqrt(X**2 + Y**2)\n",
    "colors=[\"red\", \"orange\", \"gold\", \"limegreen\", \"k\", \n",
    "        \"#550011\", \"purple\", \"seagreen\"]\n",
    "cmap = ListedColormap(colors)\n",
    "g =ax.contourf(X, Y, Z, cmap=cmap)\n",
    "plt.colorbar(g)\n",
    "###################### spectram  ######################################\n",
    "x = np.cumsum(np.random.random(1024) - 0.2)\n",
    "data, freqs, bins, im =ax.specgram(x, NFFT=128, Fs=44100, noverlap=0,cmap='plasma',xextent=(0,30))\n",
    "#Fs is the sample rate. x axis is time(sec), y axis is frequency intensity (Hz)\n",
    "#the frequency is converted by fast fourier transform\n",
    "###################### a hexagonal binning plot  ######################\n",
    "x = np.random.standard_normal(10000)\n",
    "y = 2.0 + 3.0 * x + 4.0 * np.random.standard_normal(n)\n",
    "xmin = x.min()\n",
    "xmax = x.max()\n",
    "ymin = y.min()\n",
    "ymax = y.max()\n",
    "hb = ax.hexbin(x, y, gridsize=50, cmap='inferno')\n",
    "ax.axis([xmin, xmax, ymin, ymax])\n",
    "cb = fig.colorbar(hb, ax=ax)\n",
    "#cmap=matplotlib.cm.Blues\n",
    "#gridsize: The number of hexagons in the x-direction, default is 100\n",
    "#a 2-D histogram with hexagonal cells and color each cell according to how many data in this cell. \n",
    "#It can be much more informative than a scatter plot\n",
    "###################Rectangle, circle, Polygon  ######################\n",
    "for p in [plt.Rectangle((0.1, 0.1), 0.3, 0.6,hatch='/'),\n",
    "          plt.Rectangle((0.5, 0.1), 0.3, 0.6,hatch='\\\\',fill=False)]:\n",
    "    ax.add_patch(p)\n",
    "#((xpoition_of_bottomleftcorner,ypoition_of_bottomleftcorner ), rectanglewidth, rectanglelength)\n",
    "\n",
    "circle1 = plt.Circle((0.5, 0.5), 0.2, color='blue')\n",
    "circle2 = plt.Circle((1, 1), 0.2, color='g', clip_on=False)\n",
    "ax.add_artist(circle1)\n",
    "ax.add_artist(circle2)\n",
    "#((xposition_of_center,yposition_of_center ), radius)\n",
    "\n",
    "rect = plt.Rectangle((0.2, 0.75), 0.4, 0.15, color='k', alpha=0.3)\n",
    "circ = plt.Circle((0.7, 0.2), 0.15, color='b', alpha=0.3)\n",
    "pgon = plt.Polygon([[0.15, 0.15], [0.35, 0.4], [0.2, 0.6]],color='g', alpha=0.5) ##([x1,y1],[x2,y2],[x3,y3])\n",
    "ax.add_patch(rect)\n",
    "ax.add_patch(circ)\n",
    "ax.add_patch(pgon)\n",
    "################### plot an image  #################################\n",
    "img=plt.imread('test.jpg') #Importing image data into Numpy arrays\n",
    "plt.imshow(img) #(image, cmap='Set3'('Greys', plt.cm.gray,plt.cm.gray_r), extent=[xmin, xmax,ymin,ymax],interpolation='nearest')\n",
    "plt.colorbar()\n",
    "\n",
    "from IPython.display import Image\n",
    "Image('test.jpg')\n",
    "################### fill_between  #################################\n",
    "X  = np.linspace(0,3,200)\n",
    "Y1 = X**2 + 3\n",
    "Y2 = np.exp(X) + 2\n",
    "ax.plot(X,Y1,lw=4)\n",
    "ax.plot(X,Y2,lw=4)\n",
    "ax.fill_between(X, Y1,Y2,color='k',alpha=.5) #filling the regions between y1 and y2 \n",
    "################### matshow  #################################\n",
    "x = [[4,2,3],[4,2,5]]\n",
    "ax.matshow(x, cmap=plt.cm.Spectral_r, interpolation='none');# Heatmap\n",
    "################### add_subplot  #################################\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(221)   #top left\n",
    "ax2 = fig.add_subplot(222)   #top right\n",
    "ax3 = fig.add_subplot(223)   #bottom left\n",
    "ax4 = fig.add_subplot(224)   #bottom right \n",
    "################### add another plot #################################\n",
    "# add another plot on the existed plot. A new plot position can be adjusted\n",
    "x=[1,2,3,4]\n",
    "y=[1,4,9,16]\n",
    "ax = fig.add_axes([0.5, 0.5, 1., 1.,])#(xmin, ymin, dx, and dy) for the subplot,\n",
    "ax.plot(x,y); \n",
    "#xmin and ymin are the coordinates of the lower left corner of the subplot, \n",
    "#dx and dy are the width and height of the subplot, with all values specified in relative units\n",
    "#where 0 is left/bottom and 1 is top/right\n",
    "################### y has two different scale axis for two curve #######\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax2 = ax1.twinx()\n",
    "t = np.linspace(0., 10., 100)\n",
    "ax1.plot(t, t ** 2, 'b-')\n",
    "ax2.plot(t, 1000 / (t + 1), 'r-')\n",
    "ax1.set_ylabel('Density (cgs)', color='red')\n",
    "ax2.set_ylabel('Temperature (K)', color='blue')\n",
    "ax1.set_xlabel('Time (s)')\n",
    "################### save a plot into a file############################\n",
    "fig.savefig('myplot.eps', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'column1name':[1,2],'column2name':[3,4]})\n",
    "#   column1name  column2name\n",
    "#0       1          3\n",
    "#1       2          4\n",
    "\n",
    "pd.DataFrame({'column1name':Series([1,2], index=['a','b']),'column2name':Series([10,20], index=['b','c'])})\n",
    "#   column1name   column2name\n",
    "#a     1.0          NaN\n",
    "#b     2.0          10.0\n",
    "#c     NaN          20.0\n",
    "\n",
    "pd.DataFrame({'column1name':{'index1':1, 'index2':2},'column2name':{'index1':3, 'index2':4}}, dtype='float')\n",
    "pd.DataFrame([[1,2],[3,4]],index=['index1','index2'],\n",
    "             columns=['column1name','column2name'], dtype='float')\n",
    "#         column1name  column2name  \n",
    "#index1      1.0         2.0\n",
    "#index2      3.0         4.0\n",
    "\n",
    "\n",
    "pd.DataFrame([[1,2],[3,4]],index=pd.Index(['index1','index2'], name='indexlevel'),\n",
    "             columns=pd.Index(['column1name','column2name'], name='columnlevel'), dtype='float')\n",
    "#columnlevel  column1name  column2name\n",
    "#indexlevel\n",
    "#index1         1.0         2.0\n",
    "#index2         3.0         4.0\n",
    "\n",
    "pd.DataFrame([[1,2],[3,4]],index=pd.Index(['index1','index2'], name='indexlevel'),\n",
    "             columns=pd.MultiIndex.from_arrays([['level1x','level1y'],['level2x','level2y']], \n",
    "            names=['level1name', 'level2name']), dtype='float')\n",
    "#level1name    level1x    level1y\n",
    "#level2name    level2x    level2y\n",
    "#indexlevel\n",
    "#index1         1.0         2.0\n",
    "#index2         3.0         4.0\n",
    "\n",
    "df=pd.DataFrame([1,2,3,4],\n",
    "                index=pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),('two', 'a'), ('two', 'b')]))\n",
    "#          0\n",
    "#one  a   1.0\n",
    "#     b   2.0\n",
    "#two  a   3.0\n",
    "#     b   4.0\n",
    "\n",
    "from collections import defaultdict\n",
    "A=defaultdict(dict)\n",
    "A['column1']['index1']=10;#B[columnindex][index]\n",
    "A       #defaultdict(dict, {'column1': {'index1': 10}})\n",
    "df=pd.DataFrame(A)\n",
    "#        column1\n",
    "#index1  10\n",
    "\n",
    "pd.Series({'indexa':1,'indexb':2},index=['indexa','indexb'])\n",
    "pd.Series({'indexa':1,'indexb':2})#\n",
    "pd.Series([1,2],index=['indexa','indexb'])\n",
    "#indexa    1\n",
    "#indexb    2\n",
    "pd.Series([1,2],index=[['indexa','indexb'],['index1','index2']])\n",
    "#indexa  index1    1\n",
    "#indexb  index2    2\n",
    "####################################################################################\n",
    "df.head#() #or (10)\n",
    "df.tail#()#only show the last 5 rows\n",
    "df.sample#(n=100) randomly pick up 100 rows\n",
    "df.describe()#show count, mean, std, min, 25%, 50%, 75%, max for each column\n",
    "\n",
    "pd.set_option('display.max_row',None)#dispay all the rows\n",
    "pd.set_option('display.max_columns',None)\n",
    "####################################################################################\n",
    "df=pd.DataFrame([[1,2],[2,4]],columns=['column1name','column2name'], dtype='float')\n",
    "df.to_csv('--.csv, index=False)\n",
    "df.to_csv('xx.stdout', na_rep='NULL', sep='|', index=False, header=False) \n",
    "#if there is a missing value, mark it as NULL\n",
    "x=df.to_dict()\n",
    "x # {'column1name': {0: 1.0, 1: 2.0}, 'column2name': {0: 2.0, 1: 4.0}}\n",
    "df1=df.copy()\n",
    "####################################################################################                  \n",
    "df=pd.DataFrame([[1,2],[3,4]],index=['index1','index2'],\n",
    "             columns=['column1name','column2name'], dtype='float')\n",
    "df[['column1name','column2name']]\n",
    "df\n",
    "#         column1name  column2name  \n",
    "#index1      1.0         2.0\n",
    "#index2      3.0         4.0\n",
    "\n",
    "df.info()\n",
    "#Index: 2 entries, index1 to index2\n",
    "#Data columns (total 2 columns):\n",
    "#column1name    2 non-null float64\n",
    "#column2name    2 non-null float64\n",
    "#dtypes: float64(2)\n",
    "#memory usage: 48.0+ bytes\n",
    "df.irow(1) #show the values in the second row\n",
    "df.iloc[1]\n",
    "df.iloc[1,:]\n",
    "df.loc['index2']\n",
    "df.ix['index2']\n",
    "#column1name    3.0\n",
    "#column2name    4.0\n",
    "df.iloc[:,:1]\n",
    "df.ix[:,:1]\n",
    "#         column1name\n",
    "#index1    1.0\n",
    "#index2    3.0\n",
    "df['column1name'] # show column1 values \n",
    "#index1    1.0\n",
    "#index2    3.0\n",
    "df.iloc[1,0]\n",
    "df.ix[1,0]\n",
    "#3\n",
    "df.ix[[1,0]] # the index change\n",
    "df.iloc[[1,0]]\n",
    "df.ix[['index2','index1'],['column1name','column2name']]\n",
    "df.loc[['index2','index1'],['column1name','column2name']]\n",
    "#         column1name  column2name\n",
    "#index2     3.0          4.0\n",
    "#index1     1.0          2.0\n",
    "df[:1] \n",
    "df.ix[:1]\n",
    "         column1name  column2name\n",
    "#index1     1.0           2.0\n",
    "\n",
    "##can use df.ix too\n",
    "df.loc[df['column1name']>0]# show all rows that the values in df['column1name'] > 0\n",
    "df.loc[df['column1name']==0,'column2name'] #show all rows that  the values in df['column1name'] = 0, only show column2name column\n",
    "df.loc[np.isclose(df['column1name'],0),'column2name']#show all rows that  the values in df['A'] = 0, only show B column\n",
    "\n",
    "df.values #become array\n",
    "#array([[ 1.,  2.],\n",
    "#       [ 3.,  4.]])\n",
    "df.index #show index list\n",
    "#Index([u'index1', u'index2'], dtype='object')\n",
    "df.index.map(str.upper)#(str.lower) or (str.title)\n",
    "#array(['INDEX1', 'INDEX2'], dtype=object)\n",
    "df.astype(int)\n",
    "#         column1name  column2name  \n",
    "#index1      1             2\n",
    "#index2      3             4\n",
    "df['column1name'].dtype #dtype('float64')\n",
    "df.columns#show column name list\n",
    "#Index([u'column1name', u'column2name'], dtype='object')\n",
    "df.index.name='Indexlevel' \n",
    "df.columns.name='Columnlevel'\n",
    "#Clumnlevel  column1name  column2name\n",
    "#Indexlevel\n",
    "#index1         1.0        2.0\n",
    "#index2         3.0        4.0\n",
    "df.rename(index={'index1':'index1_newname'}, columns={'column1name':'column1name_newname'},inplace=True)\n",
    "df.rename(index=str.upper,columns=str.upper, inplace=True)\n",
    "#                 COLUMN1NAME_NEWNAME    COLUMN2NAME\n",
    "#INDEX1_NEWNAME          1.0             2.0\n",
    "#INDEX2                  3.0             4.0\n",
    "\n",
    "#shuffle rows\n",
    "df=df.reindex(np.random.permutation(df.index))\n",
    "df=df.take(np.random.permutation(len(df)))\n",
    "\n",
    "df=df.reindex(index=['index2','index1'], columns=['column2name','column3name'],method='ffill')\n",
    "#         column2name  column3name\n",
    "#index2     4.0         NaN\n",
    "#index1     2.0         NaN\n",
    "#fill_value=0, method :'bfill' (or ’ffill’, 'nearest')\n",
    "#ffill: use last valid value to fill missing value #bfill: next valid value # nearest: nearest valid value\n",
    "df=df.reset_index()\n",
    "#    index    column1name   column2name\n",
    "#0   index1      1.0           2.0\n",
    "#1   index2      3.0           4.0\n",
    "df=df.set_index(['column1name','column2name' ], drop=False)#the unique values in column1 and column2 become two-level indexes \n",
    "#if drop=True, the new columns won't include the column1 and column2\n",
    "#                          column1name   column2name\n",
    "#column1name  column2name\n",
    "#   1.0          2.0           1.0          2.0\n",
    "#   3.0          4.0           3.0          4.0\n",
    "####################################################################################\n",
    "df=pd.DataFrame([[1,np.nan],[3,4]],index=['index1','index2'],\n",
    "             columns=['column1name','column2name'], dtype='float')\n",
    "#         column1name  column2name  \n",
    "#index1      1.0         NaN\n",
    "#index2      3.0         4.0\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "#          column1name  column2name\n",
    "#index2       3.0         4.0\n",
    "df.dropna(subset=['column1name'],inplace=True) \n",
    "#   column1name  column2name  \n",
    "#index1      1.0         NaN\n",
    "#index2      3.0         4.0\n",
    "df.dropna(axis=1,inplace=True)\n",
    "#        column1name\n",
    "#index1    1.0\n",
    "#index2    3.0\n",
    "df.dropna(how='all', thresh=None,inplace=True)\n",
    "#how='all'('any'), drop a row that are all NA\n",
    "#thresh=int value : you specify a minimum number of non-null values for the row/column to be kept\n",
    "df.fillna(0,inplace=True)#_=\n",
    "df['column2name'].fillna(df['column2name'].mean(), inplace=True)#, df['A'] will be replaced#\n",
    "df.fillna({'column2name':-1},inplace=True)#, replace nan with -1 in the 'column2name' column\n",
    "df.fillna(method='ffill',inplace=True) #ffill: use last valid value to fill missing value\n",
    "#method={‘bfill’,‘ffill’}, #bfill: next valid value\n",
    "df.isnull()\n",
    "#         column1name    column2name\n",
    "#index1    False           True\n",
    "#index2    False           False\n",
    "df.isnull().any(axis=0)\n",
    "#column1name    False\n",
    "#column2name     True\n",
    "df.isnull().sum(axis=0)#show how many nan in each feature\n",
    "#column1name    0\n",
    "#column2name    1\n",
    "df.notnull()\n",
    "#        column1name   column2name\n",
    "#index1    True          False\n",
    "#index2    True          True\n",
    "####################################################################################\n",
    "df=pd.DataFrame([[1,2],[2,4],[3,6],[4,10]],columns=['column1name','column2name'], dtype='float')\n",
    "#     column1name  column2name\n",
    "#0       1.0         2.0\n",
    "#1       2.0         4.0\n",
    "#2       3.0         6.0\n",
    "#3       4.0         10.0\n",
    "df.corr()#show correlation between two variables(two columns)\n",
    "#              column1name  column2name\n",
    "#column1name    1.000000     0.982708\n",
    "#column2name    0.982708     1.000000 1\n",
    "df.column1name.corr(df.column2name)#=0.98270762982399085\n",
    "df.corrwith(df.column1name)#show correlation values between column1 and other columns\n",
    "#column1name    1.000000\n",
    "#column2name    0.982708\n",
    "df.cov()#show the covariance between two variables(columns)\n",
    "#              column1name   column2name\n",
    "#column1name    1.666667     4.333333\n",
    "#column2name    4.333333    11.666667\n",
    "\n",
    "df.skew() #show each feature skew number# less skew means feature value close to 0\n",
    "#column1name    0.000000\n",
    "#column2name    0.752837\n",
    "from scipy.stats import skew\n",
    "skew(df, axis=0) #show each feature's skewness\n",
    "#array([ 0.        ,  0.43465076])\n",
    "          \n",
    "df.sum()\n",
    "#column1name    10.0\n",
    "#column2name    22.0\n",
    "df.sum(axis=1, skipna=True)\n",
    "#0     3.0\n",
    "#1     6.0\n",
    "#2     9.0\n",
    "#3    14.0\n",
    "df.mean(axis=1, skipna=True)\n",
    "df.mad(axis=1, skipna=True) #show sum(abs(xi-meanx))/number of x (mean absolute deviation of the values) for each column (row) \n",
    "df.var(axis=1, skipna=True) #show sum((xi-meanx)**2)/(number of x -1)\n",
    "df.std(axis=1, skipna=True) #show sqrt(var) for each column\n",
    "df.median(axis=1, skipna=True)# show the median value in each column\n",
    "df.max(axis=1, skipna=True) #show the largest value in each column\n",
    "df.min(axis=1, skipna=True) #show the smallest value in each column\n",
    "df.pct_change()#if the values in a column are 1,2,3, it will become NaN, (2-1)/1, (3-2)/2\n",
    "#     column1name  column2name\n",
    "#0         NaN         NaN\n",
    "#1     1.000000     1.000000\n",
    "#2     0.500000     0.500000\n",
    "#3     0.333333     0.666667\n",
    "df['column1name']/df['column1name'].shift(1)-1\n",
    "df['column1name'].pct_change()\n",
    "#0         NaN\n",
    "#1    1.000000\n",
    "#2    0.500000\n",
    "#3    0.333333\n",
    "(df==0).sum(axis=1) # how many zeros in each row\n",
    "#0    0\n",
    "#1    0\n",
    "#2    0\n",
    "#3    0\n",
    "df.count()#count non_NA values for each columns\n",
    "#column1name    4\n",
    "#column2name    4\n",
    "df.cumprod(skipna=True)\n",
    "df.cumsum(skipna=True)# if the values in a column are 1,2,3, it will become 1, 3, 6\n",
    "#     column1name  column2name\n",
    "#0       1.0         2.0\n",
    "#1       3.0         6.0\n",
    "#2       6.0        12.0\n",
    "#3      10.0        22.0\n",
    "df.quantile([0,0.5,1]) # 0(show minvalue) ,1(show maxvalue),0.5(median value)\n",
    "#      column1name   column2name\n",
    "#0.0      1.0           2.0\n",
    "#0.5      2.5           5.0\n",
    "#1.0      4.0          10.0\n",
    "####################################################################################\n",
    "df=pd.DataFrame([[1,5.0],[10,4],[5,10]],index=['index2','index1','index3'],\n",
    "             columns=['column1name','column2name'], dtype='float')\n",
    "#         column1name   column2name\n",
    "#index2      1.0          5.0\n",
    "#index1      10.0         4.0\n",
    "#index3      5.0          10.0\n",
    "df.sort_values(by='column1name',ascending=True, inplace=True)  #Sort by the values along either axis\n",
    "df.sort_index(by='column1name',ascending=True, inplace=True)\n",
    "#        column1name   column2name\n",
    "#index2    1.0           5.0\n",
    "#index3    5.0          10.0\n",
    "#index1    10.0          4.0\n",
    "#(by=['column1name','column2name']) sort by the values in column1name first and then column2name if column1name have the same values\n",
    "df.rank(axis= 0)#replace each value with its ranking along axis 0 or 1, the ranking of the smallest value is 1\n",
    "#        column1name   column2name\n",
    "#index2     1.0          2.0\n",
    "#index1     3.0          1.0\n",
    "#index3     2.0          3.0\n",
    "df.idxmax(axis= 0, skipna=True)#show an index that has the largest value in each column\n",
    "#column1name    index1\n",
    "#column2name    index3\n",
    "df.idxmin(axis= 0, skipna=True)#show an index that has the smallest value in each column\n",
    "df['column1name'].argsort() #will sort the df['column1name'] values \n",
    "#index2    0\n",
    "#index1    2\n",
    "#index3    1\n",
    "df['column1name'].argsort()[::-1] \n",
    "#index3    1\n",
    "#index1    2\n",
    "#index2    0\n",
    "df['column1name'].isin([1,'g'])#see if each value is 1 or 'g'\n",
    "#index2     True\n",
    "#index1    False\n",
    "#index3    False\n",
    "#Name: column1name, dtype: bool\n",
    "df['column1name'].order(ascending=False)#, Sort by the values along either axis#(ascending=False)from largest to smallest\n",
    "#index1    10.0\n",
    "#index3     5.0\n",
    "#index2     1.0\n",
    "df['column1name'].value_counts().sort_index(axis=0, ascending=True)\n",
    "#1.0     1\n",
    "#5.0     1\n",
    "#10.0    1\n",
    "#Name: column1name, dtype: int64\n",
    "df['column1name'].unique()\n",
    "#array([  1.,  10.,   5.])\n",
    "df['column1name'].nunique() #3\n",
    "####################################################################################\n",
    "df=pd.DataFrame([['one',1],['one',1],['two',2],['one',2]],\n",
    "             columns=['column1name','column2name'], dtype='float')\n",
    "#   column1name column2name\n",
    "#0   one           1\n",
    "#1   one           1\n",
    "#2   two           2\n",
    "#3   one           2\n",
    "df.duplicated()#see if each row is a duplicate \n",
    "#0    False\n",
    "#1     True\n",
    "#2    False\n",
    "#3    False\n",
    "\n",
    "df.drop_duplicates('column1name')#drop the #1 and #3 rows#keep the first duplicate of column1\n",
    "#   column1name column2name\n",
    "#0   one           1\n",
    "#2   two           2\n",
    "df.drop_duplicates('column1name',keep='last')#drop the #0 and #1 rows   #keep the last duplicate of column1\n",
    "#   column1name column2name\n",
    "#2   two           2\n",
    "#3   one           2\n",
    "df.drop_duplicates(['column1name','column2name'])#drop the #1 row   #keep the first duplicate of column1 and column2\n",
    "#   column1name column2name\n",
    "#0   one           1\n",
    "#2   two           2\n",
    "#3   one           2\n",
    "####################################################################################\n",
    "df=pd.DataFrame([[1,10],[2,20],[3,30]],index=['index1','index2','index3'],\n",
    "                columns=['column1name','column2name'], dtype='float')\n",
    "#        column1name  column2name\n",
    "#index1      1.0         10.0\n",
    "#index2      2.0         20.0\n",
    "#index3      3.0         30.0\n",
    "df.values.flatten()\n",
    "#array([  1.,  10.,   2.,  20.,   3.,  30.])\n",
    "df.shift(2,axis=0) #move data down by 2 indexes  #(-2,axis=0) move data up by 2 indexes\n",
    "#       column1name  column2name\n",
    "#index1      NaN         NaN\n",
    "#index2      NaN         NaN\n",
    "#index3      1.0        10.0\n",
    "df.drop(['index1','index2'], axis=0)\n",
    "#        column1name  column2name\n",
    "#index3      3.0         30.0\n",
    "df.drop(['column1name'], axis=1)\n",
    "#        column1name  \n",
    "#index1      1.0        \n",
    "#index2      2.0         \n",
    "#index3      3.0 \n",
    "del df['column1name'] #delete 'column1name' column\n",
    "df.replace(10, 100,inplace=True) #replace 10 values in df with 100 #([100,1002], np.nan, inplace=True)\n",
    "#        column1name  column2name\n",
    "#index1      1.0         100.0\n",
    "#index2      2.0         20.0\n",
    "#index3      3.0         30.0\n",
    "df.replace([1,2], np.nan, inplace=True)\n",
    "#        column1name  column2name\n",
    "#index1      NaN         10.0\n",
    "#index2      NaN         20.0\n",
    "#index3      3.0         30.0\n",
    "####################################################################################\n",
    "df=pd.DataFrame([[1,2],[2,4],[3,6],[4,10]],columns=['column1name','column2name'], dtype='float')\n",
    "df['column1name'].map(np.log)#log the values in df['column1name']\n",
    "#0    0.000000\n",
    "#1    0.693147\n",
    "#2    1.098612\n",
    "#3    1.386294\n",
    "df['column1name'].map({1:'A',3:'B'})\n",
    "#0      A\n",
    "#1    NaN\n",
    "#2      B\n",
    "#3    NaN\n",
    "df['column1name'].map(str.lower)#(str.upper)\n",
    "df['column1name'].map(lambda x: '%.2f' % x)\n",
    "df.applymap(lambda x: '%.2f')\n",
    "#0    1.00\n",
    "#1    2.00\n",
    "#2    3.00\n",
    "#3    4.00\n",
    "df['column1name'].map(lambda x : int(x))\n",
    "df['column1name'].apply(lambda x : int(x))\n",
    "df.apply(lambda x: x.max(), axis=0)\n",
    "#column1name     4.0\n",
    "#column2name    10.0\n",
    "df.apply(lambda x: x.min(), axis=0)\n",
    "df.apply(lambda x : x.dropna(), axis=1) # delete a row that all elements are nan\n",
    "def g(x): \n",
    "    return Series([x.min(),x.max()], index=('min','max'))\n",
    "df.apply(g)\n",
    "#      column1name  column2name\n",
    "#min     1.0           2.0\n",
    "#max     4.0          10.0\n",
    "df.apply(pd.value_counts)\n",
    "#     column1name  column2name\n",
    "#1.0      1.0         NaN\n",
    "#2.0      1.0         1.0\n",
    "#3.0      1.0         NaN\n",
    "#4.0      1.0         1.0\n",
    "#6.0      NaN         1.0\n",
    "#10.0     NaN         1.0\n",
    "df.apply(pd.value_counts).fillna(0)\n",
    "df.applymap(lambda x: '%.2f' %x)\n",
    "####################################################################################\n",
    "df=pd.DataFrame([[1,2],[3,4],[5,6]],\n",
    "                index=pd.MultiIndex.from_arrays([['index_1','index_2','index_3'],['index_A','index_C','index_B']], \n",
    "            names=['indexlevel1', 'indexlevel2']),\n",
    "                columns=pd.MultiIndex.from_arrays([['column1','column2'],['columnA','columnB']], \n",
    "            names=['columnlevel1', 'columnlevel2']))\n",
    "#             columnlevel1   column1   column2\n",
    "#             columnlevel2   columnA   columnB\n",
    "#indexlevel1  indexlevel2\n",
    "#index_1      index_A          1        2\n",
    "#index_2      index_C          3        4\n",
    "#index_3      index_B          5        6\n",
    "\n",
    "#df has two-level index, two-level columns\n",
    "df.index.names     #FrozenList([u'indexlevel1', u'indexlevel2'])\n",
    "df.columns.names   #FrozenList([u'columnlevel1', u'columnlevel2'])\n",
    "df.swaplevel(0,1,axis=0)#(i, j, axis), Swap levels i and j in a Multilevel on a particular axis\n",
    "#             columnlevel1   column1   column2\n",
    "#             columnlevel2   columnA   columnB\n",
    "#indexlevel2  indexlevel1\n",
    "#index_A      index_1          1         2\n",
    "#index_C      index_2          3         4\n",
    "#index_B      index_3          5         6\n",
    "\n",
    "\n",
    "df.sortlevel(1) #sort the level 2 index# original is to sort level 1 index\n",
    "#             columnlevel1   column1   column2\n",
    "#             columnlevel2   columnA   columnB\n",
    "#indexlevel1  indexlevel2\n",
    "#index_1      index_A          1        2\n",
    "#index_3      index_B          5        6\n",
    "#index_2      index_C          3        4\n",
    "df.sum(level='indexlevel1')#the index level become only level 1\n",
    "#columnlevel1   column1   column2\n",
    "#columnlevel2   columnA   columnB\n",
    "#indexlevel1\n",
    "#index_1           1        2\n",
    "#index_2           3        4\n",
    "#index_3           5        6\n",
    "df.sum(level='columnlevel1', axis=1)# the column level only become column 1 level\n",
    "#             columnlevel1   column1   column2\n",
    "#indexlevel1  indexlevel2\n",
    "#index_1      index_A          1        2\n",
    "#index_2      index_C          3        4\n",
    "#index_3      index_B          5        6\n",
    "####################################################################################\n",
    "df=pd.DataFrame([1,2,3,4],\n",
    "                index=pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),('two', 'a'), ('two', 'b')],names=['indexlevel1', 'indexlevel2']))\n",
    "#                         0\n",
    "#indexlevel1 indexlevel2\n",
    "#one            a        1.0\n",
    "#               b        2.0\n",
    "#two            a        3.0\n",
    "#               b        4.0\n",
    "df.unstack(0)\n",
    "#                0\n",
    "#indexlevel1    one  two\n",
    "#indexlevel2\n",
    "#a               1   3\n",
    "#b               2   4\n",
    "df.unstack(1)\n",
    "df.unstack()\n",
    "df.unstack('indexlevel2')\n",
    "#                0\n",
    "#indexlevel2     a  b\n",
    "#indexlevel1\n",
    "#one             1  2\n",
    "#two             3  4\n",
    "\n",
    "df=pd.DataFrame([[1,2,3,4],[5,6,7,8]],\n",
    "                columns=pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),('two', 'a'), ('two', 'b')], \n",
    "                                                  names=['columnlevel1', 'columnlevel2']))              \n",
    "#columnlevel1     one    two\n",
    "#columnlevel2    a  b   a  b\n",
    "#0               1  2   3  4\n",
    "#1               5  6   7  8\n",
    "df.unstack(0)\n",
    "#columnlevel1  columnlevel2   \n",
    "#one           a             0    1\n",
    "#                            1    5\n",
    "#              b             0    2\n",
    "#                            1    6\n",
    "#two           a             0    3\n",
    "#                            1    7\n",
    " #             b             0    4\n",
    "#                            1    8\n",
    "df=pd.DataFrame([[1,2],[3,4]],index=['a','b'], columns=['one','two'])\n",
    "#    one  two\n",
    "#a    1    2\n",
    "#b    3    4\n",
    "df.stack()\n",
    "#a  one    1\n",
    "#   two    2\n",
    "#b  one    3\n",
    "#   two    4\n",
    "####################################################################################\n",
    "df1=pd.DataFrame([[1,2],[3,4]], columns=['one','two'])\n",
    "#   one  two\n",
    "#0   1    2\n",
    "#1   3    4\n",
    "df2=pd.DataFrame([[10,np.nan],[30,40]], columns=['one','two'])\n",
    "#    one   two\n",
    "#0   10    NaN\n",
    "#1   30    40\n",
    "\n",
    "df1.append(df2,ignore_index=True)\n",
    "#    one  two\n",
    "#0    1   2.0\n",
    "#1    3   4.0\n",
    "#2   10   NaN\n",
    "#3   30  40.0\n",
    "df1.align(df2, join='inner')\n",
    "#(   one  two\n",
    "# 0    1    2\n",
    "# 1    3    4,    one   two\n",
    "# 0   10   NaN\n",
    "# 1   30  40.0)\n",
    "          \n",
    "df1+df2\n",
    "df1.add(df2)\n",
    "#    one   two\n",
    "#0   11    2\n",
    "#1   33    44\n",
    "df1.add(df2, fill_value=0)\n",
    "#    one   two\n",
    "#0   11    2\n",
    "#1   33    44\n",
    "df1.sub(df2)\n",
    "df1.subtract(df2)\n",
    "#    one   two\n",
    "#0   -9    NaN\n",
    "#1   -27   -36\n",
    "df1.multiply(df2)\n",
    "df1.div(df2)#the values in df1 / the values in df2\n",
    "df1.divide(df2)\n",
    "\n",
    "df1.sum(1)\n",
    "#0    3\n",
    "#1    7\n",
    "df1.div(df1.sum(1), axis=0)##normalize each row\n",
    "df1.T\n",
    "#      0  1\n",
    "#one   1  3\n",
    "#two   2  4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=pd.Series([10,5,20,15],index=['indexa','indexb','indexc','indexd'])\n",
    "#indexa    10\n",
    "#indexb     5\n",
    "#indexc    20\n",
    "#indexd    15\n",
    "#dtype: int64\n",
    "\n",
    "s[::2]   #show every other row\n",
    "#indexa    10\n",
    "#indexc    20\n",
    "s.values #array([10,  5, 20, 15], dtype=int64)\n",
    "s.index  #Index([u'indexa', u'indexb', u'indexc', u'indexd'], dtype='object')\n",
    "s.reindex(['indexa','a','indexb'], fill_value=0)#(range(4), method='ffill)\n",
    "#a          0\n",
    "#indexa    10\n",
    "s.name='population'\n",
    "s.index.name='indexname'\n",
    "s\n",
    "#indexname\n",
    "#indexa    10\n",
    "#indexb     5\n",
    "#indexc    20\n",
    "#indexd    15\n",
    "#Name: population, dtype: int64\n",
    "s.describe()\n",
    "#count     4.000000\n",
    "#mean     12.500000\n",
    "#std       6.454972\n",
    "#min       5.000000\n",
    "#25%       8.750000\n",
    "#50%      12.500000\n",
    "#75%      16.250000\n",
    "#max      20.000000\n",
    "s.index.is_unique #True    # see if the index are unique (the same index wont have more than one value)\n",
    "s.unique()        #array([10,  5, 20, 15], dtype=int64) \n",
    "s.rank(ascending=False)#the ranking of the largest value is 1\n",
    "#indexa    3.0\n",
    "#indexb    4.0\n",
    "#indexc    1.0\n",
    "#indexd    2.0\n",
    "s.order(ascending=False)\n",
    "s.sort_values(ascending=False)\n",
    "#indexc    20\n",
    "#indexd    15\n",
    "#indexa    10\n",
    "#indexb     5\n",
    "s.sort_index()    #Sort by the index along either axis\n",
    "#indexa    10\n",
    "#indexb     5\n",
    "#indexc    20\n",
    "#indexd    15\n",
    "s.value_counts(sort=True, ascending=False)\n",
    "#15    1\n",
    "#5     1\n",
    "#20    1\n",
    "#10    1\n",
    "s.quantile([0,0.5,1])# 0(minvalue),1(maxvalue),0.5(median value)\n",
    "#0.0     5.0\n",
    "#0.5    12.5\n",
    "#1.0    20.0\n",
    "s.isnull()\n",
    "#indexa    False\n",
    "#indexb    False\n",
    "#indexc    False\n",
    "#indexd    False\n",
    "s.notnull()\n",
    "#indexa    True\n",
    "#indexb    True\n",
    "#indexc    True\n",
    "#indexd    True\n",
    "s.dropna()\n",
    "#indexa    10\n",
    "#indexb     5\n",
    "#indexc    20\n",
    "#indexd    15\n",
    "s.drop(['indexa','indexb'])\n",
    "#indexc    20\n",
    "#indexd    15\n",
    "s.fillna(s.mean())\n",
    "s.fillna(s.median())\n",
    "s.isin([5,10])\n",
    "#indexa     True\n",
    "#indexb     True\n",
    "#indexc    False\n",
    "#indexd    False\n",
    "s.replace(10,100)# replace value 10 with 100#\n",
    "s.replace([10,5], 100)# replace value 10 and 5 with 100\n",
    "s.replace({10:100,5:50})#replace 10 with 100, 5 with 50\n",
    "s.replace([10,5],[100,50])#replace 10 with 100, 5 with 50\n",
    "#########################################################\n",
    "s=pd.Series([1,2,3],index=[['indexa','indexb','indexc'],['index1','index2', 'index3']])\n",
    "#indexa  index1    1\n",
    "#indexb  index2    2\n",
    "#indexc  index3    3\n",
    "s['indexa']#=s[0] show the values in index a\n",
    "#index1    1\n",
    "s[0]\n",
    "s['indexa','index1']\n",
    "#1\n",
    "s['indexa':'indexb']\n",
    "s.ix[['indexa','indexb']]\n",
    "#indexa  index1    1\n",
    "#indexb  index2    2\n",
    "s[:,'index1']#show the values in index1\n",
    "#indexa    1\n",
    "s.unstack()\n",
    "#         index1  index2  index3\n",
    "#indexa    1.0     NaN     NaN\n",
    "#indexb    NaN     2.0     NaN\n",
    "#indexc    NaN     NaN     3.0\n",
    "#########################################################\n",
    "s1=pd.Series([1,2],index=['indexa','indexb'])\n",
    "s2=pd.Series([10,20],index=['indexa','index1'])\n",
    "s1.add(s2, fill_value=0)\n",
    "#index1    20.0\n",
    "#indexa    11.0\n",
    "#indexb     2.0\n",
    "#########################################################\n",
    "s.plot()\n",
    "s1=s.copy()#s1 is  a copy of s\n",
    "s.to_frame()#Convert Series to DataFrame\n",
    "s.to_csv('xx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame([['a',1,2],['b',3,4],['c',5,6]],columns=['column1name','column2name','column3name'])\n",
    "#    column1name  column2name  column3name\n",
    "#0        a            1           2\n",
    "#1        b            3           4\n",
    "#2        c            5           6\n",
    "pd.melt(df, id_vars=['column1name'], value_vars=['column2name'], var_name='myVarname', value_name='myValname')\n",
    "#    column1name    myVarname    myValname\n",
    "#0      a         column2name       1\n",
    "#1      b         column2name       3\n",
    "#2      c         column2name       5\n",
    "#########################################################\n",
    "df=DataFrame({'A': ['a', 'b', 'a'], 'B': [1, 2, 3]})\n",
    "pd.get_dummies(df, prefix='X_')\n",
    "#    B  X__a   X__b\n",
    "#0   1    1      0\n",
    "#1   2    0      1\n",
    "#2   3    1      0\n",
    "s=pd.Series(['a','b','a'])\n",
    "pd.get_dummies(s)\n",
    "#   a   b\n",
    "#0  1   0\n",
    "#1  0   1\n",
    "#2  1   0\n",
    "#########################################################\n",
    "df=pd.DataFrame([21,23,25,24],columns=['column1name'], dtype='float')\n",
    "bins=[20,22,24,26]\n",
    "group_names = ['Low', 'Good', 'Great']\n",
    "A=pd.cut(df['column1name'], bins,right=True)\n",
    "#0    (20, 22]\n",
    "#1    (22, 24]\n",
    "#2    (24, 26]\n",
    "#3    (22, 24]\n",
    "#Name: column1name, dtype: category\n",
    "#Categories (3, object): [(20, 22] < (22, 24] < (24, 26]]\n",
    "pd.value_counts(A)\n",
    "#(22, 24]    2\n",
    "#(24, 26]    1\n",
    "#(20, 22]    1\n",
    "#Name: column1name, dtype: int64\n",
    "pd.cut(df['column1name'], bins,right=False)\n",
    "#0    [20, 22)\n",
    "#1    [22, 24)\n",
    "#2    [24, 26)\n",
    "#3    [24, 26)\n",
    "#Name: column1name, dtype: category\n",
    "#Categories (3, object): [[20, 22) < [22, 24) < [24, 26)]\n",
    "A=pd.cut(df['column1name'], bins,labels=group_names,right=True)\n",
    "#0      Low\n",
    "#1     Good\n",
    "#2    Great\n",
    "#3     Good\n",
    "#Name: column1name, dtype: category\n",
    "#Categories (3, object): [Low < Good < Great]\n",
    "pd.value_counts(A)\n",
    "#Good     2\n",
    "#Great    1\n",
    "#Low      1\n",
    "#Name: column1name, dtype: int64\n",
    "pd.cut(df['column1name'],3, precision=1)\n",
    "#0      (21, 22.3]\n",
    "#1    (22.3, 23.7]\n",
    "#2      (23.7, 25]\n",
    "#3      (23.7, 25]\n",
    "#Name: column1name, dtype: category\n",
    "#Categories (3, object): [(21, 22.3] < (22.3, 23.7] < (23.7, 25]]\n",
    "pd.qcut(df['column1name'],3) #each bin interval has the same number of data points\n",
    "#0    [21, 23]\n",
    "#1    [21, 23]\n",
    "#2    (24, 25]\n",
    "#3    (23, 24]\n",
    "#Name: column1name, dtype: category\n",
    "#Categories (3, object): [[21, 23] < (23, 24] < (24, 25]]\n",
    "#########################################################\n",
    "df=pd.DataFrame([1,2,3,4,5],columns=['column1name'], dtype='float')\n",
    "####data average method \n",
    "pd.rolling_mean(df['column1name'], 3, min_periods=2)#it becomes NaN, NaN, 2(mean of 1+2+3), 3, 4#take 3 values to average\n",
    "#min_periods=2 for the values are NaN, recalculate by taking 2 values to average, it become NaN 1.5, 2,3,4\n",
    "#0    NaN\n",
    "#1    1.5\n",
    "#2    2.0\n",
    "#3    3.0\n",
    "#4    4.0\n",
    "#Name: column1name, dtype: float64\n",
    "pd.ewma(df['column1name'], span=2)#exponentially weighted moving average\n",
    "#alpha=2/1+span, a=1-alpha\n",
    "#x1, (x2+a*x1)/1+a, (x3+a*x2+(a*a)*x1)/(1+a+a^2), ....#more closer to data distribution than rolling mean\n",
    "#0    1.000000\n",
    "#1    1.750000\n",
    "#2    2.615385\n",
    "#3    3.550000\n",
    "#4    4.520661\n",
    "#Name: column1name, dtype: float64\n",
    "\n",
    "from scipy.stats import percentileofscore\n",
    "x=[1, 2, 3, 4]\n",
    "percentileofscore(x, 3)  #75.0 #100% of 75 members are <= 3\n",
    "\n",
    "functionA=lambda x: percentileofscore(x, 3)\n",
    "pd.rolling_apply(df['column1name'], 2, functionA)\n",
    "#0      NaN\n",
    "#1    100.0  #how many percentage of 1,2 less than or equal to 3 : 100\n",
    "#2    100.0  #how many percentage of 2,3 less than or equal to 3 : 100\n",
    "#3     50.0  #how many percentage of 3,4 less than or equal to 3 : 50\n",
    "#4      0.0  #how many percentage of 4,5 less than or equal to 3 : 0\n",
    "\n",
    "df=pd.DataFrame({'column1name':[1,2,3,4,5],'column2name':[10,20,35,40,50]})\n",
    "pd.rolling_corr(df['column1name'], df['column2name'], 3, min_periods=2)#moving sample correlation\n",
    "#take every 3 value of df['column1name'] and df['column2name'], calculate their correlation\n",
    "#0         NaN\n",
    "#1    1.000000\n",
    "#2    0.993399\n",
    "#3    0.960769\n",
    "#4    0.981981\n",
    "# fit linear regression\n",
    "model=pd.ols(y=df['column1name'], x=df['column2name'], window=3)#every 3th row show the linear slope and intercept\n",
    "model.beta\n",
    "#        x     intercept\n",
    "#2   0.078947  0.289474\n",
    "#3   0.092308  0.076923\n",
    "#4   0.128571  -1.357143\n",
    "#########################################################\n",
    "df1=pd.DataFrame({'df1column2':['a','b','a'],'df1column1':[1,2,3]})\n",
    "df2=pd.DataFrame({'df2column1':[1,3,2]}, index=['a','b','c'])\n",
    "#df1                                    df2\n",
    "#    df1column1       df1column2            df2column1\n",
    "#0       1                a             a       1\n",
    "#1       2                b             b       3\n",
    "#2       3                a             c       2\n",
    "pd.merge(df1, df2, left_on='df1column2', right_index=True)\n",
    "#   df1column1         df1column2   df2column1\n",
    "#0      1                    a          1\n",
    "#2      3                    a          1\n",
    "#1      2                    b          3\n",
    "pd.merge(df1, df2, left_on='df1column2', right_index=True,how='outer')\n",
    "pd.merge(df1, df2, left_on='df1column2', right_index=True,how='right')#based on df2 key\n",
    "#   df1column1         df1column2   df2column1\n",
    "#0      1                    a          1\n",
    "#2      3                    a          1\n",
    "#1      2                    b          3\n",
    "#2     NaN                   c          2\n",
    "pd.merge(df1, df2, left_on='df1column2', right_index=True,how='left')#based on df1 key\n",
    "#   df1column1         df1column2   df2column1\n",
    "#0      1                    a          1\n",
    "#1      2                    b          3\n",
    "#2      3                    a          1\n",
    "pd.merge(df1, df2, left_on='df1column2', right_index=True,how='right')#based on df2 key\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "df1=pd.DataFrame({'key':['a','b','a'],'df1column1':[1,2,3]})\n",
    "df2=pd.DataFrame({'df2column1':[1,3,2],'key':['a','b','c']})\n",
    "#df1                                    df2\n",
    "#    df1column1          key                df2column1   key\n",
    "#0       1                a             0       1         a\n",
    "#1       2                b             1       3         b\n",
    "#2       3                a             2       2         c\n",
    "pd.merge(df1, df2, on='key')#df1column1 key df2column1,\n",
    "#   df1column1              key     df2column1\n",
    "#0      1                    a          1\n",
    "#2      3                    a          1\n",
    "#1      2                    b          3\n",
    "df1.join(df2, lsuffix='_left', rsuffix='_right',how='outer')#df1column1 key_left df2column1 key_right\n",
    "#    df1column1   key_left   df2column1  key_right\n",
    "#0       1          a           1           a\n",
    "#1       2          b           3           b\n",
    "#2       3          a           2           c\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "df1=pd.DataFrame({'common1':['a','b','a'],'common2':['F', 'M', 'F'],'df1column1':[1,2,3]})\n",
    "df2=pd.DataFrame({'df2column1':[1,3,2],'common1':['a','b','c'],'common2':['F','M','M']})\n",
    "#df1                                    df2\n",
    "#    common1  common2  df1column1       common1   common2  df2column1\n",
    "#0       a      F          1        0      a         F       1\n",
    "#1       b      M          2        1      b         M       3\n",
    "#2       a      F          3        2      c         M       2\n",
    "pd.merge(df1, df2, on=['common1','common2'])\n",
    "#  common1  common2  df1column1  df2column1\n",
    "#0   a        F          1           1\n",
    "#1   a        F          3           1\n",
    "#2   b        M          2           3\n",
    "pd.merge(df1, df2, on='common1', suffixes=('_left','_right'))\n",
    "#  common1 common2_left df1column1  common2_right   df2column1\n",
    "#0   a        F            1           F               1\n",
    "#1   a        F            3           F               1\n",
    "#2   b        M            2           M               3\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#if the columns in df1 are df1column1 and key1(a, b, a..), index is 0,1,2\n",
    "#if the columns in df2 are df2column1 and key2(a, b, b..), index is 0,1,2\n",
    "pd.merge(df1, df2, left_on='key1',right_on='key2')\n",
    "#key1 df1column1 df2column1 key2\n",
    "# a                          a  \n",
    "# a                          a \n",
    "# b                          b \n",
    "\n",
    "#if df1 has index:a c e, df2 has index: a c d \n",
    "pd.merge(df1, df2, left_index=True,right_index=True)\n",
    "df1.join(df2, how='outer')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#if the columns in df1 are df1column1 and key1(a, b, a..), index is 0,1,2\n",
    "#if the columns in df2 are df2column1 and key2(a, b, b..), index is 0,1,2\n",
    "pd.merge(df1, df2, left_on='key1',right_on='key2')\n",
    "#key1 df1column1 df2column1 key2\n",
    "# a                          a  \n",
    "# a                          a \n",
    "# b                          b \n",
    "\n",
    "#if df1 has index:a c e, df2 has index: a c d \n",
    "pd.merge(df1, df2, left_index=True,right_index=True, how='outer')\n",
    "df1.join(df2, how='outer')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "df1=pd.DataFrame({'df1column1':[1,2,3]}, index=['a','b','a'])\n",
    "df2=pd.DataFrame({'df2column1':[1,3,2]} ,index=['a','b','c'])\n",
    "#df1                            df2\n",
    "#    df1column1                 df2column1\n",
    "#a       1                    a       1\n",
    "#b       2                    b       3\n",
    "#a       3                    c       2\n",
    "pd.merge(df1, df2, left_index=True,right_index=True)\n",
    "f1.join(df2)\n",
    "#   df1column1  df2column1\n",
    "#a      1           1\n",
    "#a      3           1\n",
    "#b      2           3\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "df1=pd.DataFrame({'df1column1':[1,2,3]})\n",
    "df2=pd.DataFrame({'df2column1':[1,3,2]})\n",
    "df1.join(df2).add_prefix('X_')       \n",
    "#   X_df1column1  X_df2column1\n",
    "#0      1             1\n",
    "#1      2             3\n",
    "#2      3             2\n",
    "#########################################################\n",
    "df1=pd.DataFrame({'df1column1':[1,2,3],'df1column2':[10,20,30]}, index=['a','b','c'])\n",
    "df2=pd.DataFrame({'df2column1':[100,300],'df2column2':[1000,3000]}, index=['a','c'])\n",
    "#df1                                 df2\n",
    "#   df1column1 df1column2            df2column1   df2column2\n",
    "#a     1         10               a      100          1000\n",
    "#b     2         20              \n",
    "#c     3         30               c      300          3000\n",
    "pd.concat([df1,df2], axis=1, keys=['L1','L2'], names=['columnlevel1','columnlevel2'])\n",
    "#'columnlevel1'       L1       L1              L2        L2\n",
    "#'columnlevel2'  df1column1  df1column2     df2column1  df2column2\n",
    "#   a                1          10             100        1000\n",
    "#   b                2          20             NaN        NaN\n",
    "#   c                3          30             300        3000\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "df1=pd.DataFrame({'A':[1,3],'B':[2,4]})\n",
    "df2=pd.DataFrame({'A':[1]})\n",
    "#df1                                   df2\n",
    "#      A         B                      A\n",
    "#0     1         2               0      1          \n",
    "#1     3         4      \n",
    "pd.concat([df1, df2])\n",
    "#    a  b\n",
    "#0   1  2\n",
    "#1   3  4\n",
    "#0  1  NaN\n",
    "pd.concat([df1, df2], ignore_index=True)\n",
    "#    a  b\n",
    "#0   1  2\n",
    "#1   3  4\n",
    "#2   1  NaN\n",
    "pd.concat([df1, df2], ignore_index=True).fillna(method = 'ffill')\n",
    "#    a  b\n",
    "#0   1  2\n",
    "#1   3  4\n",
    "#2   1  4\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~`\n",
    "s1=pd.Series([1,2], index=['a','c'])\n",
    "s2=pd.Series([3,4], index=['a','b'])\n",
    "# s1    s2     \n",
    "# a 1   a 3   \n",
    "# c 2   b 4                            \n",
    "pd.concat([s1,s2])\n",
    "#a    1\n",
    "#c    2\n",
    "#a    3\n",
    "#b    4\n",
    "pd.concat([s1,s2], axis=1)\n",
    "#   0     1\n",
    "#a  1     3\n",
    "#b  NaN   4\n",
    "#c  2.0  NaN\n",
    "pd.concat([s1,s2], axis=1,join='inner')#join='inner', delete a row that has NaN\n",
    "#  0    1\n",
    "#a 1   3\n",
    "pd.concat([s1,s2], axis=1,join='inner', join_axes=[['a','b']]) #select which index want to show\n",
    "#   0     1\n",
    "#a  1     3\n",
    "#b  NaN   4\n",
    " \n",
    "pd.concat([s1,s2], keys=['one','two'])\n",
    "#one  a    1\n",
    "#     c    2\n",
    "#two  a    3\n",
    "#     b    4\n",
    "pd.concat([s1,s2], axis=1, keys=['one','two'])\n",
    "#  one   two\n",
    "#a  1     3\n",
    "#b  Nan   4\n",
    "#c  2    NaN\n",
    "#########################################################\n",
    "df1=pd.DataFrame({'A':[np.nan, 3],'B':[2,4]})\n",
    "df2=pd.DataFrame({'A':[1,100,200]})\n",
    "#df1                                   df2\n",
    "#      A         B                     A\n",
    "#0     NaN       2               0     1          \n",
    "#1     3         4               1     100\n",
    "#                                2     200\n",
    "                                 \n",
    "df1.combine_first(df2)#patch miss data of df1 from df2\n",
    "#      A         B              \n",
    "#0     1         2                   \n",
    "#1     3         4  \n",
    "#2   200.0      NaN\n",
    "df1.update(df2, overwrite=True)\n",
    "df1\n",
    "#      A         B              \n",
    "#0     1         2                   \n",
    "#1   100         4 \n",
    "#########################################################\n",
    "df=pd.DataFrame({'column1':['a','a','b'],'column2':[10,20,30]})\n",
    "#df                            \n",
    "#    column1 column2          \n",
    "#0     a         1              \n",
    "#1     a         2              \n",
    "#2     b         3  \n",
    "pd.crosstab(df.column1, df.column2)#the unique values of df.column1 is the index,\n",
    "#column2   10    20   30\n",
    "#column1\n",
    "#a         1     1    0\n",
    "#b         0     0    1\n",
    "pd.crosstab(df.column1, df.column2, margins=True)\n",
    "#column2   10    20   30  All\n",
    "#column1\n",
    "#a         1     1    0   2\n",
    "#b         0     0    1   1\n",
    "#All       1     1    1   3\n",
    "#########################################################\n",
    "df=pd.DataFrame({'column1':['a','a','a','b','b','b'],'column2':[10,10,20,20,30,30],'column3':[1,2,3,4,5,6]})\n",
    "#   column1  column2  column3\n",
    "#0     a       10       1\n",
    "#1     a       10       2\n",
    "#2     a       20       3\n",
    "#3     b       20       4\n",
    "#4     b       30       5\n",
    "#5     b       30       6\n",
    "df['column3'].groupby(df['column1']).mean()\n",
    "df.groupby(df['column1'])['column3'].mean()\n",
    "#column1\n",
    "#a    2\n",
    "#b    5\n",
    "df.groupby(df['column1'],as_index=False)['column3'].mean()\n",
    "#      column1  column3\n",
    "#0        a        2\n",
    "#1        b        5\n",
    "df['column3'].groupby([df['column1'],df['column2']]).mean()\n",
    "#column1  column2\n",
    "#a        10         1.5\n",
    "#         20         3.0\n",
    "#b        20         4.0\n",
    "#         30         5.5\n",
    "#Name: column3, dtype: float64\n",
    "df.groupby(df['column1']).mean()\n",
    "#           column2      column3\n",
    "#column1\n",
    "#a         13.333333      2.0\n",
    "#b         26.666667      5.0\n",
    "df.groupby('column1').mean().add_prefix('A_') \n",
    "#          A_column2     A_column3\n",
    "#column1\n",
    "#a         13.333333      2.0\n",
    "#b         26.666667      5.0\n",
    "df.groupby('column1').size()#the times appearing\n",
    "#column1\n",
    "#a    3\n",
    "#b    3\n",
    "df.groupby('column1').quantile(0.5)#(or 1,0, 0.5)\n",
    "#0.5       column2      column3\n",
    "#column1\n",
    "#a         10            2.0\n",
    "#b         30            5.0\n",
    "df.groupby('column1').describe()\n",
    "df.groupby('column1').agg(['mean', 'std'])\n",
    "#              column2           column3\n",
    "#          mean        std      mean       std\n",
    "#column1\n",
    "#a       13.333333   5.773503    2         1.0\n",
    "#b       26.666667   5.773503    5         1.0\n",
    "def functionA(x):\n",
    "    return x.max()-x.min()\n",
    "df.groupby('column1').agg(['mean', 'std','max','min','count',functionA, np.var, 'sum'])\n",
    "df.groupby('column1').agg([('meannewname','mean'), ('stdnewname','std')]) #change mean and std names\n",
    "df.groupby('column1').agg({'column2':['max','min'],'column3':'sum'})\n",
    "df.groupby('column1').transform(np.mean)#(functionA)\n",
    "#    column2     column3\n",
    "#0   13.333333      2\n",
    "#1   13.333333      2\n",
    "#2   13.333333      2\n",
    "#3   26.666667      5\n",
    "#4   26.666667      5\n",
    "#5   26.666667      5\n",
    "def functionB(df, n=2, column='column2'):\n",
    "    return df.sort_index(by=column)[-n:]\n",
    "df.groupby('column1').apply(functionB, n=2, column='column3')\n",
    "#          column1   column2   column3\n",
    "#column1\n",
    "#a       1    a        10         2 \n",
    "#        2    a        20         3\n",
    "#b       4    b        30         5\n",
    "#        5    b        30         6\n",
    "def functionC(x):\n",
    "    return {'min':x.min(), 'max':x.max()}\n",
    "df.groupby('column1').apply(functionC)\n",
    "#column1\n",
    "#a    {u'max': [u'a', 20, 3], u'min': [u'a', 10, 1]}\n",
    "#b    {u'max': [u'b', 30, 6], u'min': [u'b', 20, 4]}\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "df=pd.DataFrame(np.arange(1,10).reshape(3,3), index=['Joy','Steve','May'],columns=['F','F','M'])\n",
    "#         F1  F2  M\n",
    "#Joy      1   2   3\n",
    "#Steve    4   5   6 \n",
    "#May      7   8   9\n",
    "A={'F':'femal','M':'male',} \n",
    "df.groupby(A, axis=1).sum()\n",
    "#      femal  male\n",
    "#Joy    3      3\n",
    "#Steve  9      6\n",
    "#May    15     9\n",
    "df.groupby(len).sum() \n",
    "#         F  F  M\n",
    "#3        8  10 12\n",
    "#5        4   5  6\n",
    "#########################################################\n",
    "df=pd.DataFrame({'column1':[1,2,3],'column2':[10,20,30],'column3':['F','F','M'],'column4':['one','two','two'],\n",
    "                 'column5':['A','A','B']})\n",
    "#   column1  column2  column3  column4  column5\n",
    "#0     1       10        F       one       A  \n",
    "#1     2       20        F       two       A  \n",
    "#2     3       30        M       two       B     \n",
    "    \n",
    "df.pivot_table(['column1', 'column2'], index=['column3', 'column4'], columns=['column5'], aggfunc=np.sum)\n",
    "#                  column1     column2\n",
    "#         column5   A    B     A    B\n",
    "#column3  column4\n",
    "#F         one     1.0  NaN   10.0  NaN \n",
    "#          two     2.0  NaN   20.0  NaN\n",
    "#M         two     NaN  3.0   NaN   30.0\n",
    "df.pivot_table(['column1', 'column2'], index=['column3', 'column4'], columns=['column5'], aggfunc=np.sum, \n",
    "               margins=True, fill_value=0)\n",
    "\n",
    "#aggfunc=len , each cell is how many values containing in this cell \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, time\n",
    "from dateutil.parser import parse\n",
    "from pandas.tseries.offsets import Day, MonthBegin, MonthEnd\n",
    "import pytz #for timezone setting\n",
    "\n",
    "datetime.now()           #datetime.datetime(2017, 8, 28, 11, 22, 34, 66000)\n",
    "datetime.now().year      #2017\n",
    "datetime.now().month\n",
    "datetime.now().day       #28\n",
    "datetime.now().minute\n",
    "datetime.now().second\n",
    "datetime.now().date()    #datetime.date(2017, 8, 28)\n",
    "datetime.now().time()    #datetime.time(11, 22, 34, 66000)\n",
    "datetime.now().strftime('%a, %d %b(%m) %Y %H:%M:%S') #'Mon, 28 Aug(08) 2017 11:34:33'\n",
    "datetime.now().replace(minute=0, second=0)           #datetime.datetime(2017, 8, 28, 11, 0, 0, 346000\n",
    "\n",
    "T1='2011-01-03';T2='1/3/2011'\n",
    "datetime.strptime(T1,'%Y-%m-%d')#datetime.datetime(2011, 1, 3, 0, 0)\n",
    "datetime.strptime(T2,'%m/%d/%Y')#datetime.datetime(2011, 1, 3, 0, 0)\n",
    "parse(T1)# datetime.datetime(2011, 1, 3, 0, 0)\n",
    "pd.to_datetime(T2)#Timestamp('2011-01-03 00:00:00')\n",
    "MonthBegin().rollforward(T1)#Timestamp('2011-02-01 00:00:00')\n",
    "MonthEnd().rollforward(T1)#Timestamp('2011-01-31 00:00:00')\n",
    "MonthBegin().rollback(T1)#Timestamp('2011-01-01 00:00:00')\n",
    "MonthEnd().rollback(T1)#Timestamp('2010-12-31 00:00:00')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "p=pd.Period('2007', freq='A-JAN');\n",
    "p.asfreq('M', how='start')#Period('2006-02', 'M')\n",
    "p.asfreq('M', how='end')#Period('2007-01', 'M')\n",
    "p.asfreq('B', how='start')#Period('2006-02-01', 'B')\n",
    "p.asfreq('B', how='end')#Period('2007-01-31', 'B')\n",
    "p.to_timestamp()#)#Period('2006-02-01', 'B')\n",
    "\n",
    "p=pd.period_range('2006','2008', freq='A-JAN')\n",
    "#PeriodIndex(['2006', '2007', '2008'], dtype='period[A-JAN]', freq='A-JAN')\n",
    "p.asfreq('M', how='end')\n",
    "#PeriodIndex(['2006-01', '2007-01', '2008-01'], dtype='period[M]', freq='M')\n",
    "p.asfreq('B', how='end')\n",
    "#PeriodIndex(['2006-01-31', '2007-01-31', '2008-01-31'], dtype='period[B]', freq='B')\n",
    "p.to_timestamp(how='end')\n",
    "#DatetimeIndex(['2006-01-31', '2007-01-31', '2008-01-31'], dtype='datetime64[ns]', freq='A-JAN')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "datetime(2011,1,2) - pd.offsets.BDay()#Timestamp('2010-12-31 00:00:00')\n",
    "datetime(2011,1,2) - pd.offsets.Day()#Timestamp('2011-01-01 00:00:00')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "A=pd.date_range('1/1/2000', periods=3, freq='M')#'2000-01-31', '2000-02-29', '2000-03-31'\n",
    "A.to_period()#PeriodIndex(['2000-01', '2000-02', '2000-03'], dtype='period[M]', freq='M')\n",
    "\n",
    "B=pd.period_range('1/1/2000', periods=3, freq='M')\n",
    "#PeriodIndex(['2000-01', '2000-02', '2000-03'], dtype='period[M]', freq='M')\n",
    "B.to_timestamp(how='end')\n",
    "#DatetimeIndex(['2000-01-31', '2000-02-29', '2000-03-31'], dtype='datetime64[ns]', freq='M')\n",
    "\n",
    "A=pd.date_range('1/1/2000', periods=3, freq='D')\n",
    "#'DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-03'], dtype='datetime64[ns]', freq='D')\n",
    "A.to_period()#PeriodIndex(['2000-01-01', '2000-01-02', '2000-01-03'], dtype='period[D]', freq='D')\n",
    "A.to_period('M')#PeriodIndex(['2000-01', '2000-01', '2000-01'], dtype='period[M]', freq='M')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "[datetime(2011,1,2),datetime(2011,1,3),datetime(2011,1,4)]\n",
    "#[datetime.datetime(2011, 1, 2, 0, 0),\n",
    "# datetime.datetime(2011, 1, 3, 0, 0),\n",
    "# datetime.datetime(2011, 1, 4, 0, 0)]\n",
    "pd.DatetimeIndex(['1/2/2011','1/3/2011','1/4/2011'])\n",
    "#DatetimeIndex(['2011-01-02', '2011-01-03', '2011-01-04'], dtype='datetime64[ns]', freq=None)\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#pd.date_range(start, end, periods, freq, normalize, tz)\n",
    "pd.date_range('1/2/2011', periods=3)\n",
    "pd.date_range('1/2/2011', periods=3,normalize=True) #if 1/1/2000 6:30:00, set to 1/1/2000 00:00:00, normalized to midnight\n",
    "pd.date_range('1/2/2011', periods=3,freq='D')\n",
    "pd.date_range('1/2/2011', '1/4/2011')\n",
    "pd.date_range(start='1/2/2011', periods=3)\n",
    "pd.date_range(end='1/4/2011', periods=3)\n",
    "#DatetimeIndex(['2011-01-02', '2011-01-03', '2011-01-04'], dtype='datetime64[ns]', freq='D')\n",
    "#freq='8h', '2D', '60T'\n",
    "#'D' calender day, 'B' business day, 'H' hourly, 'T' Minutely, 'S' secondly, 'L' msec, 'U': microsec\n",
    "# 'M'   last calendar day of each month, 'BM'   last buiness day of each month\n",
    "# 'MS' first calendar day of each month, 'BMS' first buiness day of each month\n",
    "#'W-MON', 'W-TUE', 'W-WED', 'W-THU', 'W-FRI', 'W-SAT', 'W-SUN' weekly on a given day\n",
    "#'WON-1MON', 'WON-2MON', 'WON-2MON'(the third Monday of each month)\n",
    "#'Q-JAN: on the dates of 01-31, 04-30, 07-31, 10-31\n",
    "#'Q-JAN',    'Q-FEB   :quartly dates on the last calendar day of every three month\n",
    "#'BQ-JAN',  'BQ-FEB   :quartly dates on the last business day of every three month\n",
    "#'QS-JAN',  'QD-FEB   :quartly dates on the first calendar day of every three month\n",
    "#'BQS-JAN','BQD-FEB   :quartly dates on the first business day of every three month\n",
    "#'A-JAN',    'A-FEB   :annual dates on the last calendar day of a given month ex: 'A-JAN' 01-31 every year\n",
    "#'BA-JAN',  'BA-FEB   :annual dates on the last business day of a given month\n",
    "#'AS-JAN',  'AS-FEB   :annual dates on the first calendar day of a given month\n",
    "#'BAS-JAN', 'BAS-FEB   :annual dates on the first business day of a given month\n",
    "#tz='UTC' (or 'US/Eastern') set time zone\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "ts=Series(np.arange(1,5), index=pd.date_range('1/2/2011', periods=4, freq='D'))\n",
    "#2011-01-02    1\n",
    "#2011-01-03    2\n",
    "#2011-01-04    3\n",
    "#2011-01-05    4\n",
    "#Freq: D, dtype: int32\n",
    "\n",
    "ts.truncate(after='1/3/2011')\n",
    "#2011-01-02    1\n",
    "#2011-01-03    2\n",
    "#Freq: D, dtype: int32\n",
    "ts['2011']#show all data in '2011'\n",
    "ts['2011-01']\n",
    "#2011-01-02    1\n",
    "#2011-01-03    2\n",
    "#2011-01-04    3\n",
    "#2011-01-05    4\n",
    "#Freq: D, dtype: int32\n",
    "ts.shift(2, freq='D')# data shift down by 2 days\n",
    "#2011-01-04    1\n",
    "#2011-01-05    2\n",
    "#2011-01-06    3\n",
    "#2011-01-07    4\n",
    "ts.groupby(MonthEnd().rollforward).mean()\n",
    "#2011-01-31    2.5\n",
    "ts.resample('2D', how='mean') #how='sum'\n",
    "ts.resample('2D', how='mean',closed='left')#closed='left'(default)\n",
    "ts.resample('2D', how='mean',label='left')#label='left'(default)\n",
    "#2011-01-02    1.5\n",
    "#2011-01-04    3.5\n",
    "#Freq: 2D, dtype: float64\n",
    "#how='sum'\n",
    "# how='ohlc' show open(first value), high(max value), low(min value), close(last value)\n",
    "#how='prod' all values are multiplied together\n",
    "ts.resample('2D', how='mean',closed='right')\n",
    "#2010-12-31    1.0\n",
    "#2011-01-02    2.5\n",
    "#2011-01-04    4.0\n",
    "#Freq: 2D, dtype: float64\n",
    "ts.resample('2D', how='mean',label='right')\n",
    "#2011-01-04    1.5\n",
    "#2011-01-06    3.5\n",
    "#Freq: 2D, dtype: float64\n",
    "ts.resample('2D', how='mean',loffset='-1D')#all index minus 1 Day\n",
    "#2011-01-01    1.5\n",
    "#2011-01-03    3.5\n",
    "#dtype: float64\n",
    "ts.groupby(lambda x: x.month).mean()\n",
    "#1    2.5\n",
    "#dtype: float64\n",
    "ts.groupby(lambda x: x.weekday).mean()  #index is Monday, Tus, Wed ...Sunday\n",
    "#0    2\n",
    "#1    3\n",
    "#2    4\n",
    "#6    1    \n",
    "#dtype: int32\n",
    "ts=ts.tz_localize('Europe/London') #set up timezone\n",
    "#2011-01-02 00:00:00+00:00    1\n",
    "#2011-01-03 00:00:00+00:00    2\n",
    "#2011-01-04 00:00:00+00:00    3\n",
    "#2011-01-05 00:00:00+00:00    4\n",
    "#Freq: D, dtype: int32\n",
    "ts=ts.tz_convert('Europe/Moscow')  # convert timezone\n",
    "#2011-01-02 03:00:00+03:00    1\n",
    "#2011-01-03 03:00:00+03:00    2\n",
    "#2011-01-04 03:00:00+03:00    3\n",
    "#2011-01-05 03:00:00+03:00    4\n",
    "#Freq: D, dtype: int32\n",
    "S=pd.date_range('1/2/2011', periods=4, freq='2D') \n",
    "#DatetimeIndex(['2011-01-02', '2011-01-04', '2011-01-06', '2011-01-08'], dtype='datetime64[ns]', freq='2D')\n",
    "ts.asof(S)\n",
    "#2011-01-02    1.0\n",
    "#2011-01-04    3.0\n",
    "#2011-01-06    4.0\n",
    "#2011-01-08    4.0\n",
    "#Freq: 2D, dtype: float64\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "ts=Series(np.arange(1,3), index=pd.date_range('1/2/2011', periods=2, freq='M'))\n",
    "#2011-01-31    1\n",
    "#2011-02-28    2\n",
    "#Freq: M, dtype: int32\n",
    "#when large date period resample to small date period\n",
    "ts.resample('W', fill_method='ffill', limit=2) #only fill the first two missing values, the rest of missing values are NaN\n",
    "#2011-02-06    1.0\n",
    "#2011-02-13    1.0\n",
    "#2011-02-20    NaN\n",
    "#2011-02-27    NaN\n",
    "#2011-03-06    2.0\n",
    "#Freq: W-SUN, dtype: float64\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "A=Series(np.arange(5), index=pd.date_range('1/1/2000', periods=5, freq='h'))\n",
    "#2000-01-01 00:00:00    0\n",
    "#2000-01-01 01:00:00    1\n",
    "#2000-01-01 02:00:00    2\n",
    "#2000-01-01 03:00:00    3\n",
    "#2000-01-01 04:00:00    4\n",
    "#Freq: H, dtype: int32\n",
    "A.between_time('01:00', '03:00')\n",
    "A.between_time(time(1,0), time(3,0))\n",
    "#2000-01-01 01:00:00    1\n",
    "#2000-01-01 02:00:00    2\n",
    "#2000-01-01 03:00:00    3\n",
    "#Freq: H, dtype: int32\n",
    "A.between_time(time(1,0), time(3,0))# the same result\n",
    "A.at_time(time(3,0))\n",
    "A[time(3,0)]\n",
    "#2000-01-01 03:00:00    3\n",
    "#Freq: H, dtype: int32\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "df=DataFrame({'time':pd.date_range('2/1/2011', periods=2, freq='M')})\n",
    "#    time\n",
    "#0  2011-02-28\n",
    "#1  2011-03-31\n",
    "pd.DatetimeIndex(df['time']).month  #array([2, 3])\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#time unit: 'Y', 'M', 'W', 'D', 'h', 'm', 's', 'ms', 'us', 'ns'\n",
    "#64-bit integer in nanosecond\n",
    "np.datetime64('2009-01-01') - np.datetime64('2008-01-01')  #numpy.timedelta64(366,'D')\n",
    "np.datetime64('2009') + np.timedelta64(20, 'D')            #numpy.datetime64('2009-01-21')\n",
    "np.timedelta64(1,'W') / np.timedelta64(1,'D')              #7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import polyfit\n",
    "x=np.array([0,2,3])\n",
    "y=np.array([0,4,6])\n",
    "polyfit(x,y,1) #array([  2.00000000e+00,  -7.69185075e-16])\n",
    "polyfit(x,y,2) #array([  6.15259634e-16,   2.00000000e+00,   1.02558010e-15])  #degree=2 poly\n",
    "\n",
    "import statsmodels.api as sm\n",
    "A=sm.OLS(y,x).fit()     #fit a line\n",
    "print A.params          #[2.]    #show the fitting slope\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "from scipy import poly1d\n",
    "#if f(x)=3x^2 + x + 5\n",
    "p=poly1d([3,1,5])\n",
    "x=[1,2]\n",
    "p(x) \n",
    "#array([ 9, 19])\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "from scipy import linalg\n",
    "x = np.random.randn(3, 2) \n",
    "Umatrix, sigma, Vmatrix= linalg.svd(x, full_matrices=True)\n",
    "Umatrix\n",
    "#array([[-0.05896357,  0.99737542, -0.0420186 ],\n",
    "#       [-0.87946859, -0.03198673,  0.47488088],\n",
    "#       [ 0.47229048,  0.06495471,  0.87904641]])\n",
    "np.diag(sigma)\n",
    "#array([[ 1.46405123,  0.        ],\n",
    "#       [ 0.        ,  0.54081416]])\n",
    "Vmatrix\n",
    "Vmatri\n",
    "#array([[ 0.99999213, -0.00396835],\n",
    "#       [-0.00396835, -0.99999213]])\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "from scipy.misc import comb\n",
    "x = np.array([1, 2])\n",
    "y = np.array([3, 4])\n",
    "comb(y, x)#y coose x\n",
    "#array([ 120.,  210.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "%time [i for i in range(5)]#will show processing time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
